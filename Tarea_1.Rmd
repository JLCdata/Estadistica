---
title: "Tarea 1"
output:
  html_document:
    df_print: paged
---

![](/Users/stino/Desktop/mds/ramos/stats/tareas/tarea1/banner.png)

<center> <h1>Tarea 1: Foundations</h1> </center>
<center><strong>CC6104: Statistical Thinking</strong></center>
#### **Integrantes :** 

- Sebastián Tinoco
- José Luis Cadiz

#### **Cuerpo Docente:**

- Profesor: Felipe Bravo M.
- Auxiliar: Sebastian Bustos e Ignacio Meza D.
            

#### **Fecha límite de entrega:**

### **Índice:**

1. [Objetivo](#id1)
2. [Instrucciones](#id2)
3. [Referencias](#id3)
2. [Primera Parte: Preguntas Teóricas](#id4)
3. [Segunda Parte: Elaboración de Código](#id5)

### **Objetivo**<a name="id1"></a>

Bienvenid@s a la primera tarea del curso Statistical Thinking. Esta tarea tiene como objetivo evaluar los contenidos teóricos de la primera parte del curso, los cuales se enfocan principalmente en análisis exploratorio de datos y conceptos introductorios de probabilidades. Si aún no han visto las clases, se recomienda visitar los enlaces de las referencias.

La tarea consta de una parte teórica que busca evaluar conceptos vistos en clases. Seguido por una parte práctica con el fín de introducirlos a la programación en R enfocada en el análisis estadístico de datos. 

### **Instrucciones:**<a name="id2"></a>

- La tarea se realiza en grupos de **máximo 2 personas**. Pero no existe problema si usted desea hacerla de forma individual.
- La entrega es a través de u-cursos a más tardar el día estipulado en la misma plataforma. A las tareas atrasadas se les descontará un punto por día.
- El formato de entrega es este mismo **Rmarkdown** y un **html** con la tarea desarrollada. Por favor compruebe que todas las celdas han sido ejecutadas en el archivo html.
- Al momento de la revisión tu código será ejecutado. Por favor verifica que tu entrega no tenga errores de compilación.
- No serán revisadas tareas desarrolladas en Python.
- Está **PROHIBIDO** la copia o compartir las respuestas entre integrantes de diferentes grupos.
- Pueden realizar consultas de la tarea a través de U-cursos y/o del canal de Discord del curso. 


### **Referencias:**<a name="id3"></a>

Slides de las clases:

- [Introduction to Statistical Thinking](https://github.com/dccuchile/CC6104/blob/master/slides/1_1_ST-intro.pdf)
- [Introduction to R](https://github.com/dccuchile/CC6104/blob/master/slides/1_2_ST-R.pdf)
- [Descriptive Statistics](https://github.com/dccuchile/CC6104/blob/master/slides/1_3_ST-explore.pdf)
- [Probability](https://github.com/dccuchile/CC6104/blob/master/slides/1_4_ST-prob.pdf)

Videos de las clases:

- Introduction to Statistical Thinking: [video1](https://youtu.be/X4SqJu6lExM) [video2](https://youtu.be/YbiQU5TTBX4)
- Introduction to R: [video1](https://youtu.be/MbeLD3hWWVo) [video2](https://youtu.be/9W_eWCy86F4) [video3](https://youtu.be/QvFXSw2-1r4) [video4](https://youtu.be/y4JY7klrbfQ)
- Descriptive Statistics: [video1](https://youtu.be/kWNskZ8_98o) [video2](https://youtu.be/_FJ8x9M4b1w) [video3](https://youtu.be/m7VBNZ2mYWI) [video4](https://youtu.be/ylGMJ_aSQk0)
- Probability: [video1](https://youtu.be/R9AVYV73m1M) [video2](https://youtu.be/zubh1jbRiKE) [video3](https://youtu.be/uiwToagp0z4) [video4](https://youtu.be/RlhN3t_VIyw) [video5](https://youtu.be/4kV1dBaeWVc) [video6](https://youtu.be/MGyXc70JdSk)


# Primera Parte: Preguntas Teóricas<a name="id4"></a>
A continuación, se presentaran diferentes preguntas que abordan las temáticas vistas en clases. Por favor responda cada una de estas preguntas de forma breve, no más de 4 o 5 lineas.

#### **Pregunta 1:**
¿Por qué la estadística es importante?, ¿Que nos permite realizar con los datos?. De algún ejemplo.

> **La estadística es importante pues nos entrega las herramientas para caracterizar la incertidumbre. En efecto, la estadística nos permite realizar 3 cosas: (i) <u>Describir</u> el mundo de una forma simplificada, (ii) <u>Decidir</u> usando datos en un contexto de incertidumbre y (iii) <u>Predecir</u> nuevas situaciones basado en los datos disponibles.  
Por ejemplo, en el contexto de ventas de teléfonos la estadística nos permite obtener el valor más repetido a través de la moda, decidir cual modelo de teléfono potenciar mediante la evaluación de tendencias y predecir las ventas futuras mediante un modelo de predicción.**

#### **Pregunta 2:**
Un amigue cercano a usted le comenta que le preocupa salir a la calle cuando hay ofertas en los helados, esto debido a que ha visto el siguiente titular en un famoso diario chileno: "El aumento en la compra de helados tiene una alta correlación con la muerte de personas en Santiago". ¿Que le recomendaría a su amigue sobre el titular leído?, ¿Debería preocuparse tanto?.

> **Le explicaria que la matriz de correlación no puede explicar causalidad, si no, simplemente grados de relación entre variables. En este caso le recomendaria no sentir temor si es que hay ofertas en los helados, ya que debe existir otra variable que aumente el número de muertes, como podria ser la epoca de vacaciones. Finalmente no deberia preocuparse tanto, pero si podria buscar otras variables que si podrian ser causantes del aumento de muertes y evaluar los grados de relación mediante una matriz de correlación.
Para más ejemplos de correlaciones sin sentido (*correlaciones espúreas*) visitar https://www.tylervigen.com/spurious-correlations
**

#### **Pregunta 3:**
Señale las diferentes aplicaciones que poseen las visualizaciones: Boxplot, histograma, gráfico de pie y scatterplot.

> **
1. Boxplot: Construidos a partir de los percentiles, su principal función es entregar información respecto a la *simetría de la distribución* de la data.  
2. Histograma: Sirve para mostrar la distribucion de valores en una variable. Nos entrega información de la *frecuencia absoluta* de cada valor o intervalo que toma la variable.  
3. Pie chart: Nos entrega información de la *frecuencia relativa* de la variable (usualmente variable categórica). Para esto, divide un círculo en diferentes segmentos, cada uno representando la frecuencia relativa de la categoría.  
4. Scatterplot: Nos permite entender la *dispersión* de los datos. Se genera a partir de un par de variables, graficando las coordenadas cartesianas de ambas variables.**

#### **Pregunta 4:**
Suponga que esta estudiando la diferencia en los sueldos de las personas que viven en Santiago y Rancagua. Suponiendo que los datos poseen outliers, ¿Que métrica de resumen utilizaría para comparar los datos?. Justifique su respuesta.

> **La métrica usada seria una que sea robusta a los outliers, una métrica que se caracteriza por esto es la mediana, la cual nos entregará el valor central de cada distribución de sueldos. Finalmente la métrica usada sería la mediana. Adicionalmente podria ser útil un boxplot de ambas distribuciones para visualizar de forma resumida sus percentiles y outliers.**

#### **Pregunta 5:**
En base al mismo dataset de sueldos para las regiones de Santiago y Rancagua, le comentan que existe un error en los datos y que estos deben ser modificados aumentando un 10% el valor original y sumando $15.000$ a cada uno de los datos. ¿Como se ve afectada la media, mediana y desviación estándar con esta modificación?. Explique a través de ecuaciones el cambio que experimentan las métricas de resumen respecto al valor original, considere para el caso de la media $\bar{X}_{old} = \dfrac{1}{m} \sum^{m}_{i=1} x_i$ y $sd_{old} = \sqrt{\dfrac{1}{(m-1)}\sum_{i=1}^{m}(x_i-\bar{x})^{2}}$ para la desviación estándar.

> 
**En el caso de la media, el promedio es deplazado por 15.000 y multiplicado por 1.1 desde su valor original. Esto lo vemos pues:
$$\dfrac{1}{m} \sum^{m}_{i=1} (x_i \cdot 1.1 + 15.000)$$
$$1.1 \cdot \dfrac{1}{m} \sum^{m}_{i=1} x_i + 15.000 \cdot \dfrac{1}{m} \sum^{m}_{i=1} 1$$
$$1.1 \cdot \bar{X}_{old} + 15.000$$
Para la desviación estándar, esta es multiplicada por el factor 1.1, "neutralizando" la suma de los 15.000. Usando el resultado anterior:  
$$\sqrt{\dfrac{1}{(m-1)}\sum_{i=1}^{m} ((1.1 \cdot x_i + 15.000) - (1.1 \cdot \bar{X}_{old} + 15.000))^2}$$
$$\sqrt{\dfrac{1}{(m-1)}\sum_{i=1}^{m} (1.1 \cdot x_i - 1.1 \cdot \bar{X}_{old})^2}$$
$$1.1 \cdot sd_{old}$$
Por último, la mediana es afectada de la misma forma que la media, esto es, multiplicada por 1.1 y desplazada en 15.000.**

#### **Pregunta 6:**
Suponga que debe responder un examen sorpresa de 10 preguntas, con 5 alternativas por cada pregunta. ¿Cual es la probabilidad de obtener mas de 5 alternativas correctas si responde de forma aleatoria todo el examen?.

**Nota:** Puede resolver el ejercicio desarrollándolo a mano o utilizando código en R. 

```{r}
# Como el experimento de tener una pregunta buena es un experimiento Bernoulli con probabilidad p=1/5 de exito, entonces P(6 o más correctas)=1-pbinom(5,10,1/5):
paste(cat('Probabilidad de tener 6 o más correctas: \n'), 1-pbinom(5,10,1/5))
```

#### **Pregunta 7:**
Supongamos que el 10% de los alumnos del curso utilizan Macintosh, el 60% utiliza Windows y el 30% utiliza Linux. Supongamos que el 50% de los usuarios de Mac, el 78% de los usuarios de Windows y el 20% de los usuarios de Linux han sucumbido bajo un terrible virus. Al seleccionar una persona al azar nos enteramos de que su sistema está infectado por el virus. ¿Cuál es la probabilidad de que sea un alumno con Windows?.

> **Se nos pide calcular $P(Windows|Virus)$. Considerando la igualdad y los valores entregados:
$$P(Virus) = P(Virus|Windows) \cdot P(Windows)+ P(Virus|Linux) \cdot P(Linux) + P(Virus|Mac) \cdot P(Mac)$$
$$P(Virus) = 0.578$$
Entonces, usando el *Teorema de Bayes*:
$$P(Windows|Virus) = \dfrac{P(Virus|Windows) \cdot P(Windows)}{P(Virus)}$$
$$P(Windows|Virus) = 0.8096$$**

#### **Pregunta 8:**
- [F] Como las variables aleatorias son funciones que nos permiten obtener valores de probabilidad, siempre podemos obtener $\mathbb{P}(X=x)>0$ evaluando en una $f(x)$ continua y discreta.
**Para el caso de V.A continuas no es posible obtener la probabilidad de obtener un valor particular, ya que siempre entregará probabilidad 0, solo es posible obtener probabilidad de un rango de valores.**
- [F] Una PDF bien definida solo puede tener valores menores a 1 y un área debajo de la curva igual a 1.
**Una PDF si puede tener valores mayores que 1, solo importa que su área bajo la curva sea igual a 1.**
- [F] La CDF puede ser representada como la integral de la PDF y PMF
**Una CDF puede ser representada como la integral de una PDF pero como una sumatoria de una PMF.**
- [F] Una CDF es definida para todo x, continua hacia la derecha y no es decreciente.
**Una CDF esta definida dentro del dominio de su espacio muestral,y basta con que solamente sea continua por intervalos en las V.A continuas de modo que sea integrable por intervalos y la CDF puede ser discreta para V.A discretas y debe ser decreciente para el caso de V.A continuas de modo que el área converja a 1.**

#### **Pregunta 9:**
Una famosa fabrica de dulces señala que solo el $5\%$ de sus dulces contienen menos de $350$ gramos. Si los dulces elaborados por la fabrica distribuyen de forma normal, con media $\mu$ y desviación estándar $11.2$. Responda las siguientes preguntas:

- a) Encuentre la media del producto.
- b) Señale el porcentaje de dulces que se encuentran sobre los $390$ gramos.

**Nota:** Puede ser útil https://www.statskingdom.com/z_table.html

> **Usando la ecuación
$$z = \dfrac{x - \mu}{\sigma}$$
y sabiendo que $z = `r qnorm(0.05)`$, obtenemos que $\mu$ es igual a `r 350 - qnorm(0.05)*11.2`  
Por otro lado, el porcentaje de dulces que se encuentran sobre los 390 gramos es igual a `r pnorm((350 - (350 - qnorm(0.05)*11.2))/11.2)`**


---

# Segunda Parte: Elaboración de Código<a name="id5"></a>

En la siguiente sección deberá resolver cada uno de los experimentos computacionales a través de la programación en R. Para esto se le aconseja que cree funciones en R, ya que le facilitará la ejecución de gran parte de lo solicitado.

### Pregunta 1: Visualización de Datos

Para esta pregunta usted deberá trabajar en base al conjunto de datos `hearth_database.csv`, el cual esta compuesto por las siguientes variables:

- target: Señala si el paciente tuvo un infarto.
- sex: Sexo de los sujetos de prueba.
- fbs: Azúcar en la sangre con ayunas. Esta variable señala solo si se encuentra <=120 o >120.
- exang: Angina de pecho inducida por el ejercicio.
- cp: Tipo de dolor de pecho.
- restecg: Resultados electrocardiográficos en reposo.
- slope: Pendiente del segmento ST máximo de ejercicio.
- ca: Número de buques principales.
- thal: Thalassemia.
- age: Edad en años.
- trestbps: Presión arterial en reposo.
- chol: colesterol sérico en mg/dl.
- thalach: Frecuencia cardíaca máxima alcanzada.
- oldpeak: Depresión del ST inducida por el ejercicio en relación con el reposo.

En base al dataset propuesto realice un análisis exploratorio de los datos (EDA). Para su análisis enfoquen el desarrollo en las siguientes tareas:

- [ ] Obtenga la media, mediana, quintiles y valores máximos desde los datos que componen el dataset.
- [ ] Obtenga la Matriz de correlación de Pearson y visualice la relación entre las variables numéricas.
- [ ] Visualice los boxplot para las variables numéricas.
- [ ] Visualice a través de un histograma como distribuyen las variables respecto a los TARGET.

**Respuesta**

```{r}
# Lectura del data set:
library(readr)
encoding <- guess_encoding("hearth_database.csv", n_max = 1000)[1, 1][[1]] # obtenemos el encoding del dataset
data<-read.table(file="hearth_database.csv",header=T,sep=",", fileEncoding = encoding)
head(data)
```

```{r}
# Dimensiones:
dim(data)
```

**En la siguiente tabla se observan la media, mediana y valores máximos que componen al dataset:**

```{r}
# Resumen:
summary(data)
```

**A continuación se muestran los quintiles de los campos númericos.**

```{r}
#slope:
quantile(data$slope,seq(0,1,0.2))
# ca:
quantile(data$ca,seq(0,1,0.2))
# thal:
quantile(data$thal,seq(0,1,0.2))
# age:
quantile(data$ï..age,seq(0,1,0.2))
# trestbps :
quantile(data$trestbps,seq(0,1,0.2))
# chol:
quantile(data$chol,seq(0,1,0.2))
# thalach:
quantile(data$thalach,seq(0,1,0.2))
# oldpeak:
quantile(data$oldpeak,seq(0,1,0.2))
```

**A continuación se calcula  Matriz de correlación de Pearson:**
 
```{r}
# oldpeak:
cor(data[7:14])

# de forma visual
library(ggplot2)
library(ggcorrplot)
ggcorrplot(cor(data[7:14]), ggtheme = ggplot2::theme_gray, outline.color = "white", hc.order = TRUE, colors = c("#6D9EC1", "white", "#E46726")) + labs(title = "Matriz de correlaciones")
```

**A continuación se muestran BoxPlot de las variables númericas:**

```{r}
# boxplot:
 boxplot(x=data[7:14],main="hearth_database")
```

**Dada la diferencia de magnitudes entre los campos, se obtendran los boxplot de manera individual:**

```{r}
# boxplot slope:
 boxplot(x=data[7],main="slope")
# boxplot ca:
 boxplot(x=data[8],main="ca")
# boxplot thal:
 boxplot(x=data[9],main="thal")
# boxplot age:
 boxplot(x=data[10],main="age")
# boxplot trestbps:
 boxplot(x=data[11],main="trestbps")
# boxplot chol:
 boxplot(x=data[12],main="chol")
# boxplot thalach:
 boxplot(x=data[13],main="thalach")
# boxplot oldpeak:
 boxplot(x=data[14],main="oldpeak")
```

**A continuación se visualiza a través de un histograma como distribuyen las variables respecto a los TARGET:**

```{r}
# Data YES y NO:
TARGET_YES<-data[data$target=='YES',]
TARGET_NO<-data[data$target=='NO',]

# YES:
hist(TARGET_YES$slope)
hist(TARGET_YES$ca)
hist(TARGET_YES$thal)
hist(TARGET_YES$ï..age)
hist(TARGET_YES$trestbps)
hist(TARGET_YES$chol)
hist(TARGET_YES$thalach)
hist(TARGET_YES$oldpeak)

# NO:
hist(TARGET_NO$slope)
hist(TARGET_NO$ca)
hist(TARGET_NO$thal)
hist(TARGET_NO$ï..age)
hist(TARGET_NO$trestbps)
hist(TARGET_NO$chol)
hist(TARGET_NO$thalach)
hist(TARGET_NO$oldpeak)
```

---

### Pregunta 2: Teorema Central del Limite

Pruebe el teorema central del limite aplicando un muestreo de la media en las distribuciones Poisson, Exponencial y una a su elección. Grafique los resultados obtenidos y señale aproximadamente el numero de muestreos necesarios para obtener el resultado esperado, pruebe esto con las siguientes cantidades de muestreo $\{10,100,1000,5000\}$. ¿El efecto ocurre con el mismo número de muestreo para todas las distribuciones?.

**Respuesta**

```{r}
# Definición de variables o estructuras necesarias para el muestreo.
n_muestras <- 5000 # numero de muestras
n_muestra <- 30 # tamaño de cada muestra

poisson <- exp <- unif <- c()
# Realizar el muestreo de las distribuciones.
for(i in 1:n_muestras) {
  poisson <- c(poisson, mean(rpois(n = n_muestra, lambda = 1))) # obtenemos muestra de 5 obs de dist Poisson con media teorica 1 
  exp <- c(exp, mean(rexp(n = n_muestra, 1/10))) # obtenemos muestra de 5 obs de dist Exponencial con media teorica 10
  unif <- c(unif, mean(runif(n = n_muestra, 0, 100))) # obtenemos muestra de 5 obs de dist Uniforme con media teorica 50
}

distribuciones <- data.frame(poisson, exp, unif)

# Código para gráficos
library(ggplot2)
ggplot(distribuciones, aes(poisson)) + geom_histogram(bins = 10, color = "black", fill = "white") + labs(title = "Distribución Poisson", x = "Promedio muestral", y = "Frecuencia")
ggplot(distribuciones, aes(exp)) + geom_histogram(bins = 10, color = "black", fill = "white") + labs(title = "Distribución Exponencial", x = "Promedio muestral", y = "Frecuencia")
ggplot(distribuciones, aes(unif)) + geom_histogram(bins = 10, color = "black", fill = "white") + labs(title = "Distribución Uniforme", x = "Promedio muestral", y = "Frecuencia")
```  

**Como pudimos ver, el *Teorema Central del Límite* se cumple a cabalidad: la media muestral se distribuye como normal independiente de la distribución de la que venga. Según los gráficos, podemos ver una convergencia distinta según distribución: la distribución *Uniforme* tiende a converger mas rápido (1000 muestras), mientras que las distribuciones *Poisson* y *Exponencial* logran su convergencia con un mayor número de muestras (5000).**

---

### Pregunta 3: Ley de los Grandes Numeros.

#### Lanzamiento de monedas
Realice el experimento de lanzar una moneda cargada 1000 veces y observe el comportamiento que tiene la probabilidad de salir cara. Para realizar el experimento considere que la moneda tiene una probabilidad de $4/5$ de salir cara. Grafique el experimento para las secuencias de intentos que van desde 1 a 1000, señalando el valor en que converge la probabilidad de salir cara.

**Respuesta**

```{r eval=TRUE}
# Simular lanzamientos
y<-c() # Vector que guarda 1 si acierta y 0 si pierde
B<-c() # Vector que guarda la probabilidad acumulada
for (lanzamientos in 1:1000) {y<-c(y,rbinom(1,1,0.8))
B<-c(B,sum(y)/lanzamientos)
}

# Gráfico de la convergencia
plot(B,type = "l",col='red',main = "Gráfico de convergencia",xlab = "# experimento", ylab = "Probabilidad")
abline(h=0.8, col='blue')
grid(nx = NULL, ny = NULL,lty = 2,      col = "gray", lwd = 2)  
cat(paste("Probabilidad de obtener cara: \n", B[1000]))
```

#### El problema de Monty Hall 

Remontándonos en la televisión del año 1963, en USA existía un programa de concursos donde los participantes debían escoger entre 3 puertas para ganar un premio soñado. El problema del concurso era que solo detrás de 1 puerta estaba el premio mayor, mientras que detrás de las otras dos habían cabras como "premio". 

Una de las particularidades de este concurso, es que cuando el participante escogía una puerta, el animador del show abría una de las puertas que no fue escogida por el participante (Obviamente la puerta abierta por el animador no contenía el premio). Tras abrir la puerta, el animador consultaba al participante si su elección era definitiva, o si deseaba cambiar la puerta escogida por la otra puerta cerrada.

Imagine que usted es participante del concurso y desea calcular la probabilidad de ganar el gran premio **si cambia de puerta** en el momento que el animador se lo ofrece. Utilizando listas/arrays/vectores simule las puertas del concurso, dejando aleatoriamente el premio en alguna posición del array. Hecho esto, genere un numero de forma aleatoria para escoger una de las puerta (posiciones de la estructura), para luego ver si cambiando de posición tendrá mayores posibilidades de ganar el premio. Genere N veces el experimento y grafique cada una de las iteraciones, tal como se hizo en el ejercicio de las monedas.

<p align="center">
  <img src="https://brilliant-staff-media.s3-us-west-2.amazonaws.com/tiffany-wang/gWotbuEdYC.png" width="350">
</p>


**Respuesta:**

```{r eval=TRUE}
# Creamos una función que simule el juego
montyhall <- function(cambiar = TRUE){
  vector.posiciones<-c(1,2,3) # Vector no aleatorio que guarda el espacio muestral de posiciones
  Puertas <- sample(1:3,3) #Puertas donde la posición que tiene el 3 es el premio
  posicion.win<<-which(Puertas == 3) # Posición donde se encuentra el premio ganador
  posicion <- sample(1:3,1) #Elección del participante
  if(posicion.win!=posicion) {posicion.mostrada<-vector.posiciones[vector.posiciones!=posicion.win &           vector.posiciones!=posicion]} else            {posicion.mostrada<-vector.posiciones[vector.posiciones!=posicion.win][1]} # Se elige el primero de forma arbitraria, se obtendria el mismo resultado con indice 2
  # Posición que muestra el animador, i.e distinta a la ganadora y distinta a la elegida por el participante
  
  Eleccion<-vector.posiciones[vector.posiciones!=posicion.mostrada & vector.posiciones!=posicion] # Se elige la posición de la puerta que no es la elección inicial, ni tampoco la posición mostrada por el animador
   
  return(Eleccion) # Retornamos la elección, esta puede que tenga el premio o no
}

# Función que simula N juegos
n_juegos <- function(n = 10000 ,cambiar_puerta = TRUE){
  z<-c() # Vector que guarda 1 si acierta y 0 si pierde
  A<-c() # Vector que guarda la probabilidad acumulada
  for (i in 1:n) {Elec=montyhall()
  win=posicion.win
  if(Elec==win) {z<-c(z,1) # si Elect=win se gana, si no, se pierde
  } else {
  z<-c(z,0)
  }
  A<-c(A,sum(z)/i) # Se suman los aciertos de la ultima iteración, lo cual permite contar el número de exitos, dividido por el número de intentos
  }
  return(A)}
A<-n_juegos()
# Gráfico de la convergencia
plot(A,type = "l",col='red',main = "Gráfico de convergencia",xlab = "# juegos", ylab = "Probabilidad")
abline(h=2/3, col='blue')
grid(nx = NULL, ny = NULL,lty = 2,      col = "gray", lwd = 2)  

cat(paste("Probabilidad de ganar al cambiar de puerta: \n", A[10000]))
```

**De los resultados obtenidos anteriormente, se observa que es más probable obtener el premio ganador si es que se cambia de puerta.**

---

### Pregunta 4: ¿Independencia?
Ustedes disponen de los dados D1 y D2, los cuales no están cargados y son utilizados para comprobar que $\mathbb{P}(AB)=\mathbb{P}(A)\mathbb{P}(B)$ cuando el evento A es independiente del B. Para estudiar la independencia considere que los eventos A y B se definen de la siguiente manera; sea A el evento dado por los valores obtenidos en el lanzamiento del dado D1, este está compuesto por $A=\{D1=1,D1=2,D1=6\}$. Por otro lado, el evento B viene dado por los valores obtenidos con el dado D2, el que está conformado por $B=\{D2=1,D2=2,D2=3,D2=4\}$. Con esto, tendremos un $\mathbb{P}(A)=1/2$, $\mathbb{P}(𝐵)=2/3$ y $\mathbb{P}(AB)=1/3$. Compruebe de forma gráfica que al realizar 1000 lanzamientos (u otro valor grande que usted desea probar) se visualiza que $\mathbb{P}(AB)=\mathbb{P}(A)\mathbb{P}(B)$. 

Hecho lo anterior, compruebe el comportamiento de un segundo grupo de eventos, dados por el lanzamiento de solo el dado D1. Donde, los eventos para D1 quedan definidos como: $A =\{D1=1,D1=2,D1=6\}$ y $B=\{D1=1,D1=2,D1=3\}$. ¿Se observa independencia en este experimento?.

Se le aconseja que para simular los lanzamientos de dados utilice la función `sample()` para generar valores aleatorios entre 1 y 6. Compruebe los números generados por la función con los casos favorables de cada uno de los eventos a ser estudiados.

**Respuesta:**

Para resolver este problema, necesitamos comprobar que $\mathbb{P}(AB)=\mathbb{P}(A)\mathbb{P}(B)$. Para esto, trabajaremos con ambos lados de la ecuación: Por una parte, obtendremos de manera empírica la probabilidad $\mathbb{P}(AB)$; por otro lado, obtendremos la multiplicación de ambas probabilidades empíricas $\mathbb{P}(A)\mathbb{P}(B)$. Una vez calculadas ambas partes, evaluaremos gráficamente si se cumple la igualdad y por lo tanto, saber si $A$ es independiente de $B$.

```{r}
# Primer grupo de eventos
N_lan = 1000 # Numero de lanzamientos
  
L_A <- c(1, 2, 6) # Lanzamientos favorables A
L_B <- c(1, 2, 3, 4) # Lanzamientos favorables B
L_AB <- c(1, 2) # Lanzamientos favorables AB

P_A <- length(L_A)/length(1:6) # probabilidad teórica de A
P_B <- length(L_B)/length(1:6) # probabilidad teórica de B
P_AB <- length(L_AB)/length(1:6) # probabilidad teórica de AB

d1 <- d2 <- A <- B <- A_B <- A_avg <- B_avg <- A_B_avg <- c()
for(i in 1:N_lan) { # loop de n lanzamientos
  
  d1_tmp <- sample(1:6, 1) # obtengo lanzamiento i del dado 1
  d2_tmp <- sample(1:6, 1) # obtengo lanzamiento i del dado 2
  
  d1 <- c(d1, d1_tmp) # guardo el resultado del dado 1
  d2 <- c(d2, d2_tmp) # guardo el resultado del dado 2
  
  if (d1_tmp %in% L_A){
    A <- c(A, 1) # caso de exito en obtener A
  } else{
    A <- c(A, 0) # caso de no exito en obtener A
  }
  
  if (d2_tmp %in% L_B){
    B <- c(B, 1) # caso de exito en obtener B
  } else{
    B <- c(B, 0) # caso de no exito en obtener B
  }
  
  if ((d1_tmp %in% L_A) & (d2_tmp %in% L_B)){
    A_B <- c(A_B, 1) # caso de exito en obtener AB 
  } else{
    A_B <- c(A_B, 0) # caso de no exito en obtener AB
  }
  
  A_avg <- c(A_avg, mean(A)) # probabilidad empirica de A con i lanzamientos
  B_avg <- c(B_avg, mean(B)) # probabilidad empirica de B con i lanzamientos
  A_B_avg <- c(A_B_avg, mean(A_B)) # probabilidad empirica de AB con i lanzamientos
  
}

A_B_mult <- A_avg * B_avg # multiplicación de ambas probabildiades (lado derecho de la ecuación)
lanzamientos = data.frame(d1, d2, A, B, A_B, A_B_avg, A_B_mult) # dataframe con los resultados

# Código para gráfico
ggplot(lanzamientos, aes(x = 1:N_lan, y = A_B_mult)) + geom_point(size = 1, color = "royalblue") + labs(title = "Independencia: Primer grupo de eventos", x = "Lanzamientos", y = "Promedio acumulado casos favorables") + geom_hline(yintercept = P_AB, color = "red", size = 1)

```

**Tal como pudimos observar, para el primer grupo de eventos se cumple la igualdad $\mathbb{P}(AB)=\mathbb{P}(A)\mathbb{P}(B)$ . Por lo tanto, concluimos que son eventos independientes.**

```{r}
# Segundo grupo de eventos
N_lan = 1000 # Numero de lanzamientos
  
L_A <- c(1, 2, 6) # Lanzamientos favorables A
L_B <- c(1, 2, 3) # Lanzamientos favorables B
L_AB <- c(1, 2) # Lanzamientos favorables AB

P_A <- length(L_A)/length(1:6) # probabilidad teórica de A
P_B <- length(L_B)/length(1:6) # probabilidad teórica de B
P_AB <- length(L_AB)/length(1:6) # probabilidad teórica de AB 

d1 <- A <- B <- A_B <- A_avg <- B_avg <- A_B_avg <- c()
for(i in 1:N_lan) { # loop de n lanzamientos
  
  d1_tmp <- sample(1:6, 1) # obtengo lanzamiento i del dado 1
  
  d1 <- c(d1, d1_tmp) # guardo el resultado del dado 1
  
  if (d1_tmp %in% L_A){
    A <- c(A, 1) # caso de exito en obtener A
  } else{
    A <- c(A, 0) # caso de no exito en obtener A
  }
  
  if (d1_tmp %in% L_B){
    B <- c(B, 1) # caso de exito en obtener B
  } else{
    B <- c(B, 0) # caso de no exito en obtener B
  }
  
  if ((d1_tmp %in% L_A) & (d1_tmp %in% L_B)){
    A_B <- c(A_B, 1) # caso de exito en obtener AB
  } else{
    A_B <- c(A_B, 0) # caso de no exito en obtener AB
  }
  
  A_avg <- c(A_avg, mean(A)) # probabilidad empirica de A con i lanzamientos
  B_avg <- c(B_avg, mean(B)) # probabilidad empirica de B con i lanzamientos
  A_B_avg <- c(A_B_avg, mean(A_B)) # probabilidad empirica de AB con i lanzamientos
  
}

A_B_mult <- A_avg * B_avg # multuplicación de ambas probabilidades (lado derecho de la ecuación)
lanzamientos <- data.frame(d1, A, B, A_B, A_B_avg, A_B_mult) # dataframe con los resultados

# Código para gráfico
ggplot(lanzamientos, aes(x = 1:N_lan, y = A_B_mult)) + geom_point(size = 1, color = "royalblue") + labs(title = "Independencia: Segundo grupo de eventos", x = "Lanzamientos", y = "Promedio acumulado casos favorables") + geom_hline(yintercept = P_AB, color = "red", size = 1)

```

**Para el segundo grupo de eventos notamos que <u>no</u> se cumple la igualdad $\mathbb{P}(AB)=\mathbb{P}(A)\mathbb{P}(B)$. Por lo tanto, concluimos que son eventos dependientes.**

---

### Pregunta 5: La Ruina del Jugador
Un amigo ludópata suyo le comenta que el truco de jugar en el casino esta en no parar de apostar y apostando lo mínimo posible. Ya que así, tienes mas probabilidades de ganar el gran pozo que acumula el juego. Usted sabiendo la condición de su amigo, decide no creer en su conjetura y decide probar esto a través de un experimento.

Para realizar el experimento usted decide asumir las siguientes declaraciones, bajo sus observaciones:

- La probabilidad de ganar en un juego del casino es $9/19$
- Sabe que su amigo posee fondos en el rango de 0 a 200 dolares.
- Las apuestas como mínimo deben ser igual a 5 dolares.
- El monto de las apuestas no cambia y son siempre igual a la primera. Por ejemplo, si su amigo apuesta 50 dolares, todos los próximos juegos apuesta 50 hasta que se acaba su dinero.

En el experimento deberá obtener la evolución de los fondos hasta que el jugador se queda sin fondos para jugar. Puede ser útil seguir la lógica de una moneda cargada para realizar esto. Pruebe esto con una apuesta igual a 5, 25 y 50 graficando los resultados. Comente los resultados obtenidos.

**Respuesta**

```{r eval=TRUE}
# Función para obtener el desarrollo de las apuestas
ruina <- function(fondos = 100, apuesta = 5){
  vec_fondos<-c()
  while (0<fondos & fondos<200) {
    if(rbinom(1,1,9/19)==1) {fondos<-fondos+apuesta} else {fondos<-fondos-apuesta}
    vec_fondos<-c(vec_fondos,fondos)}
  return(vec_fondos) # Devuelve un vector con el desarrollo de los fondos
}

plot(ruina(), type="l", col="blue", xlab="N° de juegos", ylab="Fondos", main="Evolución de los fondos (apuesta = 5)")
plot(ruina(apuesta = 25), type="l", col="blue", xlab="N° de juegos", ylab="Fondos", main="Evolución de los fondos (apuesta = 25)")
plot(ruina(apuesta = 50), type="l", col="blue", xlab="N° de juegos", ylab="Fondos", main="Evolución de los fondos (apuesta = 50)")
```

**A partir de los gráficos anteriores e iterando varias veces sobre el comportamiento de estos gráficos, se puede inferir que la probabilidad de cumplir la meta de llegar a 200 dolares cuando se apuestan 5 dolares, es muy baja ya que los incrementos son muy pequeños y considerando que la probabilidad de perder es mayor, existe una clara tendencia a perder al apostar muchas veces (sobre 100 apuestas).**

**Por otro lado, para el caso de apostar 25 o 50 dolares se observa que existe una mayor probabilidad de poder cumplir la meta al existir más chance de alcanzar la meta al obtener mayores ganancias.**

**Finalmente se concluye que el amigo no estaba en lo correcto.**

&nbsp;
<hr />
<p style="text-align: center;">A work by <a href="https://github.com/dccuchile/CC6104">CC6104</a></p>

<!-- Add icon library -->
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.1/css/all.css">

<!-- Add font awesome icons -->
<p style="text-align: center;">
    <a href="https://github.com/dccuchile/CC6104"><i class="fab fa-github" style='font-size:30px'></i></a>
</p>

&nbsp;