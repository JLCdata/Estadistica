---
title: "Tarea 4"
output:
  html_document:
    df_print: paged
---

![](banner.png)

<center> <h1>Tarea 4: Bayesian Inference Part I</h1> </center>
<center><strong>CC6104: Statistical Thinking</strong></center>
#### **Integrantes :** 

- Alumno 1
- Alumno 2

#### **Cuerpo Docente:**

- Profesor: Felipe Bravo M.
- Auxiliar: Sebastian Bustos e Ignacio Meza D.
            

#### **Fecha límite de entrega:**

### **Índice:**

1. [Objetivo](#id1)
2. [Instrucciones](#id2)
3. [Referencias](#id3)
2. [Primera Parte: Preguntas Teóricas](#id4)
3. [Segunda Parte: Elaboración de Código](#id5)

### **Objetivo**<a name="id1"></a>

Bienvenid@s a la primera tarea del curso Statistical Thinking. Esta tarea tiene como objetivo evaluar los contenidos teóricos de la primera parte del curso, los cuales se enfocan principalmente en introducirlos en la estadística bayesiana. Si aún no han visto las clases, se recomienda visitar los enlaces de las referencias.

La tarea consta de una parte teórica que busca evaluar conceptos vistos en clases. Seguido por una parte práctica con el fin de introducirlos a la programación en R enfocada en el análisis estadístico de datos. 

### **Instrucciones:**<a name="id2"></a>

- La tarea se realiza en grupos de **máximo 2 personas**. Pero no existe problema si usted desea hacerla de forma individual.
- La entrega es a través de u-cursos a más tardar el día estipulado en la misma plataforma. A las tareas atrasadas se les descontará un punto por día.
- El formato de entrega es este mismo **Rmarkdown** y un **html** con la tarea desarrollada. Por favor compruebe que todas las celdas han sido ejecutadas en el archivo html.
- Al momento de la revisión tu código será ejecutado. Por favor verifica que tu entrega no tenga errores de compilación.
- No serán revisadas tareas desarrolladas en Python.
- Está **PROHIBIDO** la copia o compartir las respuestas entre integrantes de diferentes grupos.
- Pueden realizar consultas de la tarea a través de U-cursos y/o del canal de Discord del curso. 


### **Referencias:**<a name="id3"></a>

Slides de las clases:

- [Introduction to Bayesian Inference](https://github.com/dccuchile/CC6104/blob/master/slides/3_1_ST-bayesian.pdf)
- [Summarizing the Posterior](https://github.com/dccuchile/CC6104/blob/master/slides/3_2_ST-posterior.pdf)


Videos de las clases:

- Introduction to Bayesian Inference: [video1](https://youtu.be/Gf2uuElPH0g) [video2](https://youtu.be/5ZZ3PTPdZQw) [video3](https://youtu.be/d_jXwM_-5jc) [video4](https://youtu.be/yZW1V3X4J94) [video5](https://youtu.be/-fw0ktR7psM) [video6](https://youtu.be/0oK9M82sw8Q) [video7](https://youtu.be/u7Qdw5rDDDU)
- Summarizing the Posterior: [video1](https://youtu.be/67o8wcZsgtk)  [video2](https://youtu.be/Xr8S1Uv_5GQ) [video3](https://youtu.be/XJKyW4tYp_0) [video4](https://youtu.be/OMipgV727wo)

Documentación:

- [rethinking](https://github.com/rmcelreath/rethinking)
- [tidyr](https://tidyr.tidyverse.org)
- [purrr](https://purrr.tidyverse.org)
- [dplyr](https://dplyr.tidyverse.org)
- [ggplot2](https://ggplot2.tidyverse.org/)

# Primera Parte: Preguntas Teóricas<a name="id4"></a>
A continuación, se presentaran diferentes preguntas que abordan las temáticas vistas en clases. Por favor responda cada una de estas preguntas de forma breve, no más de 4 o 5 lineas.

#### **Pregunta 1:**

Explique cual es la diferencia fundamental entre la estadística bayesiana y frecuentista.

> Las principal diferencia es que en el enfoque frecuentista las probabilidades corresponden a frecuencias limite con el objetivo de obtener una medida objetiva del mundo, y los parametros de una distribucion de probabilidad son una constante fija desconocida. Por otro lado, en el enfoque Bayesiano la probabilidad es una creencia o conocimiento a priori y los parametros de una distribución de probabilidad son tratados como variables aleatorias.

#### **Pregunta 2:**

Discuta la siguiente afirmación **La inferencia bayesiana permite fácilmente utilizar distintos tipos de información**.

> Esto hace referencia al factor de probabilidad a priori, en donde se pueden incorporar creencias o conocimiento experto sobre que conjetura es más pluasible dado los datos. Esto en la practica permite manipular la distribución a posterior. 

#### **Pregunta 3:**

Explique la diferencia entre **prior probability** y **posterior probability**

> La prior probability son las creencias iniciales que se tienen sobre las conjeturas posibles con las cuales fueron producidos los datos obtenidos. Por otro lado, la posterir probability es la distribucion de probabilidad de las conjeturas dado los datos obtenidos, teniendo en cuenta las creencias iniciales.

#### **Pregunta 4:**

El estadista bayesiano "Bruno Finetti" menciona la siguiente frase en su libro de probabilidad:  **La probabilidad no existe**. Lo que en verdad quizo decir es que la probabilidad es un método para describir incertidumbre en un observador con conocimiento limitado. Discuta esta información utilizando el ejemplo del lanzamiento del globo terraqueo visto en clases. ¿Que significa decir "la probabilidad de que sea agua es 0.7"?

> Cuando se dice que la probabilidad de que sea agua es 0.7 mediante inferencia Bayesiana, esto quiere decir 0.7 es el valor "más probable" según los datos obtenidos,  esto quiere decir que realmente "la probabilidad de agua" realmente es la posterior distribution, siendo 0.7 el valor que la maximiza.


#### **Pregunta 5:**
¿ Que ventaja entrega que la distribución de la posterior este en la misma familia de distribución de probabilidad que la del prior?. De un ejemplo de alguna distribución que posee este comportamiento.

> La ventaja es que la probabilidad de los datos tiene una forma cerrada y por tanto se puede calcular una expresion analitica sin necesidad de tener que acudir a metodos computacionales. Un ejemplo es el caso cuando likelihood es binomial y el prior es uniforme, obteniendose una posterior distribution beta.

#### **Pregunta 6:**
Señale y explique los pasos de la *grid approximation* para obtener la posterior y responda las siguientes preguntas:

a. ¿Cual de los pasos señalados nos permite obtener una distribución de la posterior mas precisa?.
b. Cuales son las limitaciones de la *grid approximation*.

> Los pasos vienen definidos por:
1. Definir la grilla de parámetros.
2. Obtener el prior para cada uno de los valores en la grilla.
3. Obtener la likelihood para cada uno de los parámetros
4. Obtener la multiplicación $prior \cdot likelihood$, la cual es una versión no estandarizada del posterior
5. Finalmente, estandarizar el posterior dividiendo cada valor por la suma de todos los valores.
En cuanto a la primera pregunta, el paso mas importante para obtener una distribución de la posterior mas precisa es el 1: definir la grilla de parámetros. La razón de esto es que si uno define una grilla con pocos parámetros, el posterior generado será una aproximación lejana del posterior real, mientras que si uno ajusta el número de parámetros a uno mas grande, el posterior generado se parecerá cada vez más al posterior real, logrando una distribución mas precisa.
Una limitación grande de esta técnica es el bajo escalado con el nivel de parámetros. Es decir, mientras más valores y parámetros se incorporan a la grilla más combinaciones de parámetros tengo, y por lo mismo, conlleva un gran tiempo de ejecución.


#### **Pregunta 7:**

¿ Por qué es necesario aprender a trabajar con muestras de la posterior?.

> La principal razón para trabajar con muestras es para responder preguntas de inferencia, las que se agrupan en:
1. Calcular intervalos de límites definidos
2. Calcular intervalos de área definida
3. Calcular un estimador puntual
Uno podría responder estas preguntas a través del posterior una vez calculado. Sin embargo, en la práctica uno no cuenta con una forma matemática cerrada del posterior, por lo que responder estas preguntas (o incluso llegar a calcular este posterior) requiere de mucho cálculo matemático, sobretodo cuando el posterior es multivariado. Para resolver esto, es posible obtener una aproximación de la respuesta a través del trabajo con muestras del posterior, lo que es mucho mas eficiente en términos de cálculo. Finalmente y como última razón, técnicas usadas como MCMC dan como resultado muestras del posterior, por lo que se hace útil aprender a extraer información de estas muestras.



#### **Pregunta 8:**
Señale si las siguientes afirmaciones son verdaderas o falsas, en el caso que sean falsas justifique su respuesta:

- [F] Los point estimates de la posterior no entregan información relevante en un estudio. 

- [F] Un intervalo de confianza  es un intervalo dentro del cual un valor de parámetro no observado cae con una probabilidad particular, mientras que un intervalo de credibilidad es un rango de valores en el que se estima que estará cierto valor desconocido.

- [F] La principal ventaja de HPDI frente a un intervalo de credibilidad es que si la posterior no distribuye de forma normal, el HPDI será capaz de detectar los puntos de interés, mientras que un intervalo de credibilidad lo ignoraría al asumir simetría.

> La primera afirmación es falsa, pues un estimador puntual si puede entregar información relevante del estudio. Un ejemplo de esto es la moda o máximo a posteriori (MAP), la que representa el valor con la mayor probabilidad del posterior.
La segunda afirmación es falsa, pues el intervalo de confianza es un intervalo que contiene el valor del parámetro no observado con probabilidad $1 - alpha$ (es decir, la probabilidad hace referencia a que el intervalo contenga el parámetro y no al revés)


#### **Pregunta 9** 

Suponga que tiene dos especies de pandas. Cada una de las especies es igual de común y es imposible distinguirlas físicamente. Una de las diferencias entre las especies es el tamaño de sus familias. Si denotamos por $\theta$ a la especie del panda se tiene que, cuando la especie es $\theta = 1$ tiene dos bebes un $10\%$ de las veces mientras que la especie $\theta = 2$ tiene dos bebes un $20\%$ de las veces, mientras que el resto de veces ambas especies tienen un solo bebe.

Suponga que usted esta intentando determinar la especie de un panda que que tiene como registro de nacimientos al conjunto $D$, considere quela especie de un panda que acaba de dar a luz a dos bebes, es decir $D = \{\text{dos bebes}\}$

- [ ] ¿Cual es la probabilidad de que pertenezca a la especie $1$?
- [ ] Suponga ahora que el mismo panda acaba de dar a luz y esta vez es solo un bebe. Calcule la probabilidad posterior de que el panda sea de especie $1$. ¿Que cambia con el calculo anterior?
- [ ] Suponga que le ofrecen hacer un test genético a su panda, como suele ser común con los test no es perfecto y le mencionan las siguientes características:

  - La probabilidad de que correctamente idenfitique a la especie $1$ es de $0.8$
  - La probabilidad de que correctamente identifique a la especie $2$ es de $0.65$

Se administra el test y se obtiene un resultado positivo a la especie $1$. Sin utilizar la información en $D$ calcule la probabilidad posterior de que su panda sea de la especie $1$. Repita sus cálculos utilizando la información recopilada en $D$. ¿En que varían sus resultados?


> Para la primera pregunta, se busca calcular la probabilidad $Pr(\theta = 1 | D = 2)$. Por teorema de bayes, sabemos que esta probabilidad equivale a:
$$Pr(\theta = 1 | D = 2) = \frac{Pr(D = 2| \theta = 1) \cdot Pr(\theta = 1)}{Pr(D = 2)}$$
Como sabemos que ambas especies son igual de comunes, establecemos un *prior* unforme, esto es:
$$Pr(\theta = 1) = Pr(\theta = 2) = 0.5$$
Por otro lado, por probabilidades totales sabemos que 
$$Pr(D = 2) = Pr(D = 2 | \theta = 1) \cdot Pr(\theta = 1) + Pr(D = 2 | \theta = 2) \cdot Pr(\theta = 2) = 0,15$$
Así, calculamos la probabilidad requerida:
$$Pr(\theta = 1 | D = 2) = \frac{0,1 \cdot 0,5}{0,15} = 0,33$$  

> Para la segunda pregunta, existen 2 enfoques para abordarla  
i. Calcular la probabilidad a través del update bayesiano, esto es, usando como prior lo calculado en la primera pregunta  
ii. Calcular la probabilidad a través de un nuevo evento único que contenga ambos nacimientos.  
Ambas metodologías llegan a resultados equivalentes. A modo de ilustrativo, se calculará la probabilidad usando ambos enfoques.  
a) Enfoque con update:
Tras haber conocido los resultados de la primera pregunta, se nos pide calcular la probabilidad $Pr(\theta = 1 | D = 1)$. Por teorema de bayes, esta probabilidad equivale a:
$$Pr(\theta = 1 | D = 1) = \frac{Pr(D = 1) | \theta = 1) \cdot Pr(\theta = 1)}{Pr(D = 1)}$$
Usando lo obtenido en la primera pregunta, actualizamos nuestro *prior*:
$$Pr(\theta = 1) = 0.33$$
Por otro lado, por probabilidades totales sabemos que:
$$Pr(D = 1) = Pr(D = 1 | \theta = 1) \cdot Pr(\theta = 1) + Pr(D = 1 | \theta = 2) \cdot Pr(\theta = 2)$$
$$Pr(D = 1) = 0,9 \cdot 0,33 + 0,8 \cdot (1 - 0,33) = 0,833$$
Finalmente, la probabilidad $Pr(\theta = 1 | D = 1)$ es equivalente a:
$$Pr(\theta = 1 | D = 1) = \frac{0,9 \cdot 0,33}{0,833} = 0,36$$
b) Enfoque con único evento:
Se nos pide calcular la probabilidad dado dos eventos, esto es $Pr(\theta = 1 | D = 2, D = 1)$. Por teorema de bayes, sabemos que esta probabilidad equivale a:
$$Pr(\theta = 1 | D = 2, D = 1) = \frac{Pr(D = 2, D = 1| \theta = 1) \cdot Pr(\theta = 1)}{Pr(D = 2, D = 1)}$$ Además, como ambos eventos son independientes, podemos asumir:
$$Pr(D = 2, D = 1 | \theta = 1) = 0,1 \cdot 0,9 = 0,09$$
y
$$Pr(D = 2, D = 1 | \theta = 2) = 0,2 \cdot 0,8 = 0,16$$
Por probabilidades totales, sabemos
$$Pr(D = 2, D = 1) = Pr(D = 2, D = 1 | \theta = 1) \cdot Pr(\theta = 1) + Pr(D = 2, D = 1| \theta = 2) \cdot Pr(\theta = 2) = 0,125$$
Así, la probabilidad requerida viene dada por
$$Pr(\theta = 1 | D = 2, D = 1) = \frac{0,09 \cdot 0,5}{0,125} = 0,36$$
Como conclusión del segundo experimento, la probabilidad es levemente superior pues la probabilidad de tener 1 hijo es mayor para la especie $\theta = 1$ que para la especie $\theta = 2$, aumentando así la probabilidad.  

> Para la tercera pregunta, se nos pide calcular la probabilidad $Pr(\theta = 1 | K = 1)$, donde $K \in {1,2}$ y representa los posibles resultados del test genético. Como en oportunidades anteriores, esta probabilidad equivale a
$$Pr(\theta = 1 | K = 1) = \frac{Pr(K = 1 | \theta = 1) \cdot Pr(\theta = 1)}{Pr(K=1)}$$
Por probabilidades totales, sabemos
$$Pr(K=1) = Pr(K=1|\theta = 1) \cdot Pr(\theta = 1) + Pr(K=1|\theta = 2) \cdot Pr(\theta = 2) = 0,8 \cdot 0,5 + 0,35 \cdot 0,5 = 0,575$$
Así, la probabilidad requerida viene dada por:
$$Pr(\theta = 1 | K = 1) = \frac{0,8 \cdot 0,5}{0,575} = 0,69$$

> Finalmente, se nos pide usar toda la información proporcionada en el enunciado para calcular la probabilidad de que el panda sea de la especie 1. Al igual que en la pregunta 2, esta pregunta puede ser resuelta a través de 2 enfoques:   
a) Enfoque con update:  Se nos pide calcular la probabilidad $Pr(\theta = 1 | K = 1)$. Por Teorema de Bayes, sabemos que esta probabilidad equivale a:
$$Pr(\theta = 1 | K = 1) = \frac{Pr(K = 1 | \theta = 1) \cdot Pr(\theta = 1)}{Pr(K = 1)}$$
Al igual que en la segunda pregunta, actualizamos el *prior*:
$$Pr(\theta = 1) = 0,36$$
Además, por probabilidades totales sabemos que:
$$Pr(K = 1) = Pr(K = 1 | \theta = 1) \cdot Pr(\theta = 1) + Pr(K = 1 | \theta = 2) \cdot Pr(\theta = 2)$$
$$Pr(K = 1) = 0,8 \cdot 0,36 + 0,35 \cdot (1 - 0,36) = 0,724$$
Entonces, la probabilidad $Pr(\theta = 1 | K = 1)$ es equivalente a:
$$Pr(\theta = 1 | K = 1) = \frac{0,8 \cdot 0,36}{0,724} = 0,56$$
b) Enfoque con único evento: Usando toda la información proporcionada por el enunciado, se nos pide calcular la probabilidad $Pr(\theta = 1 | D = 1, D = 2, K = 1)$. Por Teorema de Bayes, sabemos que esta probabilidad equivale a:
$$Pr(\theta = 1 | D = 1, D = 2, K = 1) = \frac{Pr(D = 1, D = 2, K = 1 | \theta = 1) \cdot Pr(\theta = 1)}{Pr(D = 1, D = 2, K = 1)}$$
Por un lado, sabemos que la probabilidad $Pr(D = 1, D = 2, K = 1 | \theta = 1)$ equivale a:
$$Pr(D = 1, D = 2, K = 1 | \theta = 1) = Pr(D = 1| \theta = 1) + Pr(D = 2| \theta = 1) + Pr(K = 1| \theta = 1)$$
$$Pr(D = 1, D = 2, K = 1 | \theta = 1) = 0,1 \cdot 0,9 \cdot 0,8 = 0,072$$
De manera similar, la probabilidad $Pr(D = 1, D = 2, K = 1 | \theta = 2)$ viene dada por:
$$Pr(D = 1, D = 2, K = 1 | \theta = 2) = Pr(D = 1| \theta = 2) \cdot Pr(D = 2| \theta = 2) \cdot Pr(K = 1| \theta = 2)$$
$$Pr(D = 1, D = 2, K = 1 | \theta = 2) = 0,2 \cdot 0,8 \cdot 0,35 = 0,056$$
Además, por probabilidades totales sabemos:
$$Pr(D = 1, D = 2, K = 1) = Pr(D = 1, D = 2, K = 1| \theta = 1) \cdot Pr(\theta = 1) + Pr(D = 1, D = 2, K = 1| \theta = 2) \cdot Pr(\theta = 2)$$
$$Pr(D = 1, D = 2, K = 1) = 0,072 \cdot 0,5 + 0,056 \cdot 0,5 = 0,0655$$
Recogiendo todos los resultados, la probabilidad requerida viene dada por:
$$Pr(\theta = 1 | D = 1, D = 2, K = 1) = \frac{0,072 \cdot 0,5}{0,0655} = 0,56$$



---

# Segunda Parte: Elaboración de Código<a name="id5"></a>
En la siguiente sección deberá resolver cada uno de los experimentos computacionales a través de la programación en R. Para esto se le aconseja que cree funciones en R, ya que le facilitará la ejecución de gran parte de lo solicitado.

Para el desarrollo preste mucha atención en los enunciados, ya que se le solicitará la implementación de métodos sin uso de funciones predefinidas. Por otro lado, Las librerías permitidas para desarrollar de la tarea 4 son las siguientes:

```{r, eval=TRUE}
# Manipulación de estructuras
library(tidyverse)
library(dplyr)
library(tidyr)
library(purrr)

# Para realizar plots
library(scatterplot3d)
library(ggplot2)
library(plotly)

# Manipulación de varios plots en una imagen.
library(gridExtra)

# Análisis bayesiano
library(rethinking)
```

Si no tiene instalada la librería “rethinking”, ejecute las siguientes líneas de código para instalar la librería:

```{r, eval=FALSE}
install.packages("rethinking")
```

En caso de tener problemas al momento de instalar la librería con el código anterior, utilice las siguiente chunk:

```{r, eval=FALSE}
install.packages(c("mvtnorm","loo","coda"), repos="https://cloud.r-project.org/",dependencies=TRUE)
options(repos=c(getOption('repos'), rethinking='http://xcelab.net/R'))
install.packages('rethinking',type='source')
```

### Preguntas: Introducción a Grid Approximation
Las primeras dos preguntas de esta tarea tienen como objetivo introducirlos en la inferencia Bayesiana utilizando la técnica Grid Approximation para obtener una aproximación de la posterior. Al finalizar los problemas ustedes deberán ser capaces de visualizar los efectos que tiene el prior en la posterior, saber cómo realizar una Grid Approximation y comprender como utilizar Percentile Interval (PI) en una posterior.

### Pregunta 1:

Considere el dataset "moneda.csv" donde se encuentran los resultados de un experimento lanzando una moneda, el objetivo de esta pregunta es estudiar mediante técnicas de inferencia Bayesiana el valor de la probabilidad de que salga cara, representado por el valor $1$. Puede usar la librerira rethinking durante toda esta pregunta (si lo desea).

```{r}
dataMoneda <- read.csv("moneda.csv", header = TRUE)
sum(dataMoneda)/1000
```

- [ ] Programe el metodo grid approximation para distintos tamaños de experimento. ¿Como van cambiando las curvas posterior?

**Definimos una grilla de 1000 valores posibles para p, variando el tamaño de la muestas en 100, 500 y 800.**

```{r}
library(plotly)


# Tamaño de la muestra 
size=100

# Muestra
muestra<-dataMoneda[sample(nrow(dataMoneda),size),]
num.unos<-sum(muestra)
num.ceros<-length(muestra)-num.unos

# Define grid
p_grid<-seq(from=0,to=1,length.out=1000)

# Define prior
prior<-rep(1,1000) # Dejamos a priori que todos los posibles valore de p tengan la misma posibilidad de ser ciertos
#plot(p_grid,prior,type="b",xlab = "probability cara",ylab= "Prior probability")
#mtext("Prior")


# Compute likelihood at each value in grid
likelihood<-dbinom(num.unos,size=length(muestra),prob=p_grid)
#plot(p_grid,likelihood,type="b",xlab = "probability cara",ylab= "Likelihood probability")
#mtext("Likelihood")

# Compute product of likelihood*prior
unstd.posterior<-likelihood*prior

# Standardize the posterior, so it sums to 1
posterior<-unstd.posterior/sum(unstd.posterior)

# Generación de df
data<-data.frame(p_grid,likelihood,posterior)

fig <- plot_ly(data,x = ~p_grid)
fig <- fig %>% add_trace(y = ~posterior,type = 'scatter', name = 'alfa 0.01',mode = 'lines')
fig <- fig %>% layout(title = sprintf("posterior probability %d muestras", size),
         xaxis = list(title = "Probabilidad cara"),
         yaxis = list (title = "Posterior probability"))
fig

# Tamaño de la muestra 
size=500

# Muestra
muestra<-dataMoneda[sample(nrow(dataMoneda),size),]
num.unos<-sum(muestra)
num.ceros<-length(muestra)-num.unos

# Define grid
p_grid<-seq(from=0,to=1,length.out=1000)

# Define prior
prior<-rep(1,1000) # Dejamos a priori que todos los posibles valore de p tengan la misma posibilidad de ser ciertos
#plot(p_grid,prior,type="b",xlab = "probability cara",ylab= "Prior probability")
#mtext("Prior")


# Compute likelihood at each value in grid
likelihood<-dbinom(num.unos,size=length(muestra),prob=p_grid)
#plot(p_grid,likelihood,type="b",xlab = "probability cara",ylab= "Likelihood probability")
#mtext("Likelihood")

# Compute product of likelihood*prior
unstd.posterior<-likelihood*prior

# Standardize the posterior, so it sums to 1
posterior<-unstd.posterior/sum(unstd.posterior)

# Generación de df
data<-data.frame(p_grid,likelihood,posterior)

fig <- plot_ly(data,x = ~p_grid)
fig <- fig %>% add_trace(y = ~posterior,type = 'scatter', name = 'alfa 0.01',mode = 'lines')
fig <- fig %>% layout(title = sprintf("posterior probability %d muestras", size),
         xaxis = list(title = "Probabilidad cara"),
         yaxis = list (title = "Posterior probability"))
fig

# Tamaño de la muestra 
size=800

# Muestra
muestra<-dataMoneda[sample(nrow(dataMoneda),size),]
num.unos<-sum(muestra)
num.ceros<-length(muestra)-num.unos

# Define grid
p_grid<-seq(from=0,to=1,length.out=1000)

# Define prior
prior<-rep(1,1000) # Dejamos a priori que todos los posibles valore de p tengan la misma posibilidad de ser ciertos
#plot(p_grid,prior,type="b",xlab = "probability cara",ylab= "Prior probability")
#mtext("Prior")


# Compute likelihood at each value in grid
likelihood<-dbinom(num.unos,size=length(muestra),prob=p_grid)
#plot(p_grid,likelihood,type="b",xlab = "probability cara",ylab= "Likelihood probability")
#mtext("Likelihood")

# Compute product of likelihood*prior
unstd.posterior<-likelihood*prior

# Standardize the posterior, so it sums to 1
posterior<-unstd.posterior/sum(unstd.posterior)

# Generación de df
data<-data.frame(p_grid,likelihood,posterior)

fig <- plot_ly(data,x = ~p_grid)
fig <- fig %>% add_trace(y = ~posterior,type = 'scatter', name = 'alfa 0.01',mode = 'lines')
fig <- fig %>% layout(title = sprintf("posterior probability %d muestras", size),
         xaxis = list(title = "Probabilidad cara"),
         yaxis = list (title = "Posterior probability"))
fig

```

**Finalmente, a partir de los graficos se observa que en la medida de que aumenta el tamaño de los datos, al parametro p que maximiza el Posterior se acerca a 0.55. A partir del dataset completo se puede ver que 551 veces ocurrieron caras de los 1000 experimentos, por lo que la probabilidad "real" fue de 0.55 de forma empirica. Con eso se concluye que en la medida de que los cantidad de datos sea mayor respecto de la población se podran obtener estimaciones más cercanas del valor real.**

- [ ] Repita el mismo análisis anterior pero utilizando el método de Laplace (no necesita programar el método, puede utilizar la libreria "rethinking"). ¿Como se comparan con los resultados anteriores?.

```{r}
library(rethinking)

# Tamaño de la muestra 
size=800

# Muestra
muestra<-dataMoneda[sample(nrow(dataMoneda),size),]
num.unos<-sum(muestra)
num.ceros<-length(muestra)-num.unos

globe.qa <- quap(
alist(
    C~dbinom( C+S ,p) , # binomial likelihood
    p~dunif(0,1)   # 
) ,
data=list(C=num.unos,S=num.ceros) )

# display summary of quadratic approximation
precis( globe.qa )
sample.quap <- extract.samples(  globe.qa )
dens(sample.quap)
```

A partir del grafico de densidad del prior se observa que se pueden hacer conclusiones similares respecto a la probabilidad de cara, es decir  en torno 0.55 aproximadamente.

- [ ] Grafique la densidad de la posterior y encuentre la proporción de los siguientes defined boundaries:

  - [ ] $(0, 0.4)$
  - [ ] $(0.4,0.7)$
  - [ ] $(0.7,1)$
  
```{r}
# Tamaño de la muestra 
size=100

# Muestra
muestra<-dataMoneda[sample(nrow(dataMoneda),size),]
num.unos<-sum(muestra)
num.ceros<-length(muestra)-num.unos

# Define grid
p_grid<-seq(from=0,to=1,length.out=1000)

# Define prior
prior<-rep(1,1000) # Dejamos a priori que todos los posibles valore de p tengan la misma posibilidad de ser ciertos


# Compute likelihood at each value in grid
likelihood<-dbinom(num.unos,size=length(muestra),prob=p_grid)


# Compute product of likelihood*prior
unstd.posterior<-likelihood*prior

# Standardize the posterior, so it sums to 1
posterior<-unstd.posterior/sum(unstd.posterior)

# Limites
inf<-0
sup<-0.4
# Rellenado de area
posterior_area<-posterior[p_grid>inf & p_grid<sup]

# Generación de df

data<-data.frame(p_grid,likelihood,posterior)

fig <- plot_ly()
fig <- fig %>% add_trace(x=~p_grid,y = ~posterior,type = 'scatter', name = 'Posterior',mode = 'lines')

fig <- fig %>% add_trace(x=p_grid[p_grid>inf & p_grid<sup],y=~posterior_area,type = 'scatter', name = 'Area de probabilidad', fill = 'tozeroy',mode = 'lines')

fig <- fig %>% layout(title = sprintf("posterior probability %d muestras", size),
         xaxis = list(title = "Probabilidad cara"),
         yaxis = list (title = "Posterior probability"))
fig

cat("Probabilidad rango 0 - 0.4 ")
sum(posterior[p_grid>inf & p_grid<sup])

# Limites
inf<-0.4
sup<-0.7
# Rellenado de area
posterior_area<-posterior[p_grid>inf & p_grid<sup]

# Generación de df

data<-data.frame(p_grid,likelihood,posterior)

fig <- plot_ly()
fig <- fig %>% add_trace(x=~p_grid,y = ~posterior,type = 'scatter', name = 'Posterior',mode = 'lines')

fig <- fig %>% add_trace(x=p_grid[p_grid>inf & p_grid<sup],y=~posterior_area,type = 'scatter', name = 'Area de probabilidad', fill = 'tozeroy',mode = 'lines')

fig <- fig %>% layout(title = sprintf("posterior probability %d muestras", size),
         xaxis = list(title = "Probabilidad cara"),
         yaxis = list (title = "Posterior probability"))
fig

cat("Probabilidad: rango 0.4 - 0.7")
sum(posterior[p_grid>inf & p_grid<sup])

# Limites
inf<-0.7
sup<-1
# Rellenado de area
posterior_area<-posterior[p_grid>inf & p_grid<sup]

# Generación de df

data<-data.frame(p_grid,likelihood,posterior)

fig <- plot_ly()
fig <- fig %>% add_trace(x=~p_grid,y = ~posterior,type = 'scatter', name = 'Posterior',mode = 'lines')

fig <- fig %>% add_trace(x=p_grid[p_grid>inf & p_grid<sup],y=~posterior_area,type = 'scatter', name = 'Area de probabilidad', fill = 'tozeroy',mode = 'lines')

fig <- fig %>% layout(title = sprintf("posterior probability %d muestras", size),
         xaxis = list(title = "Probabilidad cara"),
         yaxis = list (title = "Posterior probability"))
fig

cat("Probabilidad: rango 0.7 - 1")
sum(posterior[p_grid>inf & p_grid<sup])
```
  

¿Como puede interpretar los resultados? 

**A partir de los graficos y probabilidades obtenidas se observa que es más probable que el parametro p este entre 0.4 y 0.7.**

- [ ] Calcule un intervalo de credibilidad al $50\%$, $75\%$ y $95\%$. ¿Como se puede interpretar los resultados? ¿Cual podría ser un problema al usar intervalos de credibilidad?.

```{r}
# Sample posterior
samples <- sample( p_grid , prob=posterior , size=1e4 ,
replace=TRUE )
dens(samples)

# 50%
quantile(samples,c(0.1,0.6))

# 75%
quantile(samples,c(0.1,0.85))

# 95%
quantile(samples,c(0.05,1))

```
**Los resultados se interpretan como que el valor del parametro p puede estar entre el rango de valores entregador con un X% de probabilidad.**
**El problema de usar intervalos de credibilidad es que se puede dar el caso de que no se este dando el rango de valores más probables. Esta corrección se puede corregir con HPDI.**

- [ ] Genere los intervalos HDPI para $50\%$, $75\%$ y $95\%$, compárelos con  los intervalos de credibilidad de la parte anterior. ¿En que se diferencian los intervalos de credibilidad con los HDPI?.

```{r}
# 50%
HPDI(samples,prob=0.5)

# 75%
HPDI(samples,prob=0.75)

# 95%
HPDI(samples,prob=0.95)


```

**Estos se diferencian que el primero asume cierta simetria de la distribución lo cual no siempre es así, y cuando este es el caso no se consideran los parametros que tienen mayor probabilidad de ocurrencia. Por otro lado HPDI si tiene esto en consideración, buscando el area que minimice el ancho de esta, de modo de asegurar que se esten considerando los valores más probables.**

---

### Pregunta 2: Grid Approximation y Posterior Predictive Distribution

El objetivo de esta pregunta es comprender el concepto de `sample prediction` visto en clases y realizar predicciones en base a una posterior. 

Un conjunto de carteros aburridos de las mordidas de perros ha decidido realizar un catastro de mordidas recibidas por los empleados de su empresa en un periodo de dos meses, planeando en base a estos datos realizar inferencia bayesiana. Los datos de las mordidas estas datos por el dataset `no+mordidas.csv`, en donde cada fila representa las mordidas recibidas por diferentes carteros y las columnas señalan si fue mordido o no el cartero en los meses de estudio (notar que si fue mordido sera señalado con un 1, de lo contrario es señalado con un 0). Cabe señalar que un cartero no puede ser mordido mas de una vez al mes, ya que el damnificado recibe licencia por todos los días restantes del mes tras la mordida, reincorporándose el siguiente mes al trabajo.


En base a los datos, realice los siguientes puntos:

- [ ] Realice una *grid approximation* para estimar la probabilidad que un cartero sea mordido, para esto junte los datos del mes 1 y 2 de estudio. Señale el máximo valor de la posterior.

```{r}
library(plotly)

# Lectura

df = read.csv("no+mordidas.csv")

# Generando dataframe con ambos meses

mes1<-df$bites_month_1
mes2<-df$bites_month_2
mordidas<-c(mes1,mes2)
data_mordida<-data.frame(mordidas)
#sum(data_mordida)/500

# Tamaño de la muestra 
size=100

# Muestra
muestra<-data_mordida[sample(nrow(data_mordida),size),]
num.unos<-sum(muestra)
num.ceros<-length(muestra)-num.unos

# Define grid
p_grid<-seq(from=0,to=1,length.out=1000)

# Define prior
prior<-rep(1,1000) # Dejamos a priori que todos los posibles valore de p tengan la misma posibilidad de ser ciertos


# Compute likelihood at each value in grid
likelihood<-dbinom(num.unos,size=length(muestra),prob=p_grid)
#plot(p_grid,likelihood,type="b",xlab = "probability cara",ylab= "Likelihood probability")
#mtext("Likelihood")

# Compute product of likelihood*prior
unstd.posterior<-likelihood*prior

# Standardize the posterior, so it sums to 1
posterior<-unstd.posterior/sum(unstd.posterior)

# Generación de df
data<-data.frame(p_grid,likelihood,posterior)

fig <- plot_ly(data,x = ~p_grid)
fig <- fig %>% add_trace(y = ~posterior,type = 'scatter', name = 'alfa 0.01',mode = 'lines')
fig <- fig %>% layout(title = sprintf("posterior probability %d muestras", size),
         xaxis = list(title = "Probabilidad cara"),
         yaxis = list (title = "Posterior probability"))
fig




cat("El maximo valor de la posterior es: ")
max(posterior)

cat("Luego, la probabilidad de que un cartero sea mordido es de: ")
p_grid[which.max(posterior)]

```


- [ ] Utilizando la posterior obtenida en el paso anterior, utilice rbinom para simular 10.000 réplicas de 500 registros de mordidas. Con esto, deberá obtener 10.000 números, cada uno de los cuales es un recuento de las mordidas obtenidas en el registro de datos. Compare la distribución del número de los carteros mordidos predichos con el número real de los datos (248 carteros mordidos de un total de 500 datos). ¿El modelo se ajusta bien a los datos? Es decir, ¿la distribución de las predicciones incluye la observación real como resultado central y probable?



```{r}
library(rethinking)
# Sample posterior
samples <- sample( p_grid , prob=posterior , size=1e4 ,
replace=TRUE )

post_pred_w <- rbinom( 1e4 , size=500 , prob=samples )


x <- post_pred_w
fit <- density(x)

plot_ly(x = x, type = "histogram", name = "Histogram") %>% 
  add_trace(x = fit$x, y = fit$y, type = "scatter", mode = "lines", fill = "tozeroy", yaxis = "y2", name = "Density") %>% 
  layout(yaxis2 = list(overlaying = "y", side = "right")) %>% layout(title = "Posterior Predictive Distribution")

cat("luego la cantidad de mordidas que maximiza la distribucion posterior es: ")
fit$x[which.max(fit$y)]

```
**Del grafico de densidad, observando el valor que maximiza la densidad, se aprecia que este valor no es cercano a 248, siendo el valor obtenido en torno a 260-270. A partir de esto se concluye que el modelo no se ajusta bien a los datos, pero si es un valor cercano teniendo en cuenta que se considera toda la incertidumbre posible en este modelamiento.**

- [ ] Como se comento en el comienzo `bites_month1` contiene las mordidas señaladas por un conjunto de personas en el primer mes. Haciendo uso de `bites_month2`, obtenga la posterior de que una persona que fue mordida en el primer mes, sea mordida nuevamente en el segundo mes. Para esto, se recomienda comenzar buscando los carteros que fueron mordidos el primer mes y en base a estos generar una búsqueda indexada para obtener el número solicitado. Hecho esto, simule ese número carteros mordidos 10.000 veces. De los resultados obtenidos, compare el recuento de carteros mordidos con el recuento real. ¿Cómo se ve el modelo desde este punto de vista?

```{r}
# Lectura

df = read.csv("no+mordidas.csv")

# Generando dataframe con ambos meses
mordidosx2<-df[df$bites_month_1==1,]$bites_month_2

# Generación de df
mordidosx2<-data.frame(mordidosx2)



# Tamaño de la muestra 
size=100

# Muestra
muestra<-mordidosx2[sample(nrow(mordidosx2),size),]
num.unos<-sum(muestra)
num.ceros<-length(muestra)-num.unos

# Define grid
p_grid<-seq(from=0,to=1,length.out=1000)

# Define prior
prior<-rep(1,1000) # Dejamos a priori que todos los posibles valore de p tengan la misma posibilidad de ser ciertos


# Compute likelihood at each value in grid
likelihood<-dbinom(num.unos,size=length(muestra),prob=p_grid)
#plot(p_grid,likelihood,type="b",xlab = "probability cara",ylab= "Likelihood probability")
#mtext("Likelihood")

# Compute product of likelihood*prior
unstd.posterior<-likelihood*prior

# Standardize the posterior, so it sums to 1
posterior<-unstd.posterior/sum(unstd.posterior)

# Generación de df
data<-data.frame(p_grid,likelihood,posterior)

fig <- plot_ly(data,x = ~p_grid)
fig <- fig %>% add_trace(y = ~posterior,type = 'scatter', name = 'alfa 0.01',mode = 'lines')
fig <- fig %>% layout(title = sprintf("posterior probability %d muestras", size),
         xaxis = list(title = "Probabilidad mordido x2"),
         yaxis = list (title = "Posterior probability"))
fig

# Sample posterior
samples <- sample( p_grid , prob=posterior , size=1e4 ,
replace=TRUE )

# Generación de datos
post_pred_w <- rbinom( 1e4 , size=148 , prob=samples )

# Visualización
x <- post_pred_w
fit <- density(x)

plot_ly(x = x, type = "histogram", name = "Histogram") %>% 
  add_trace(x = fit$x, y = fit$y, type = "scatter", mode = "lines", fill = "tozeroy", yaxis = "y2", name = "Density") %>% 
  layout(yaxis2 = list(overlaying = "y", side = "right")) %>% layout(title = "Posterior Predictive Distribution")

cat("luego la cantidad de mordidas que maximiza la distribucion posterior es: ")
fit$x[which.max(fit$y)]

cat("luego la cantidad de mordidas reales fue: ")
sum(mordidosx2)

```
**En este caso se observa que el modelo se ajusta de muy buena forma a los datos.**

---

### Pregunta 3: Inferencia Sobre Dos Parámetros

En esta pregunta se trabajara con el dataset "notas.csv" el cual contiene las notas históricas de un curso desconocido. Suponga que los datos vienen de una distribución $\mathcal{N}(\mu,\sigma^2)$, el objetivo de la pregunta es estudiar el comportamiento de los datos y los posibles valores de $\mu,\sigma$ mediante técnicas de inferencia Bayesiana.

Usted sabe un dato extra sobre la información, los valores de $\sigma$ en la grilla se mueven en el intervalo $[0.5,1.5]$ y, además, tiene una fuerte creencia a que es mas probable encontrar la desviación estándar real entre $[0.5,1]$ que en $(1,1.5]$. De hecho, estudios señalan que la probabilidad de encontrar sigma en los valores $[0.5,1]$ es de 2/3, mientras que 1/3 para el resto de intervalos.


- [ ] Modifique el siguiente código que permite realizar una grid approximation para $2$ parámetros. Proponga priors para $\mu$ y $\sigma$, justifique su elección.


```{r}
library(rethinking)
library(dplyr)
library(gridExtra)

# Leer información
data_notas <- read.csv("notas.csv")

# Función para crear likelihood dado mu y sigma
grid_function <- function(mu, sigma){
   output <- prod(dnorm(x = data_notas$Notas, mean = mu, sd = sigma)) # Funcion de likelihood
   return(output)
}

# Valores de la grilla
n_grid <- 500
grid_mu <- seq(from = 1, to = 7, length.out = n_grid)
grid_sigma <- c(seq(from = 0.5, to = 1, length.out = n_grid/2), seq(from = 1, to = 1.5, length.out = n_grid/2))

# Se crea la grilla 2d (combinacion de cada valor posible)
data_grid <- expand_grid(grid_mu, grid_sigma)

# Se guarda la likelihoo
data_grid$likelihood <- map2(data_grid$grid_mu, data_grid$grid_sigma, grid_function)

# Se transforma el forma de map2 a una columna
data_grid <- unnest(data_grid,cols = c("likelihood"))


# Valores de los priors
prior_mu <- rep(1, n_grid) # asumiendo que el prior es uniforme
prior_sigma <-  c(rep(2, n_grid/2), rep(1, n_grid/2))

# Se crea la grilla 2d de priors
prior <- expand_grid(prior_mu,prior_sigma)

# Se calculan los valores del prior
data_grid$prior <-  map2(prior$prior_mu,prior$prior_sigma, prod)
data_grid <- unnest(data_grid,cols = c("prior"))

# Se calcula el posterior
data_grid$unstd_posterior <-  data_grid$likelihood * data_grid$prior

# Se estandariza el posterior
data_grid$posterior <- data_grid$unstd_posterior/sum(data_grid$unstd_posterior)

# Se ajustan los valores de la posterior para que no sean valores tan pequeños
data_grid$posterior <- (data_grid$posterior - min(data_grid$posterior))/(max(data_grid$posterior)-min(data_grid$posterior))

```

> **En primer lugar, notamos que por el enunciado el prior de $\sigma$ viene dado por la grilla $[0.5, 1.5]$, siendo 2 veces más probable el intervalo $[0.5,1]$ que el intervalo $(1,1.5]$. Por otro lado y como no sabemos nada ex-ante sobre la media $\mu$, podemos generar un prior conservador del intervalo $[1, 7]$. Si bien es un prior costoso computacionalmente,  es a la vez conveniente, pues se abarca la totalidad del intervalo en el que las notas están definidas.**

- [ ] Tras haber ejecutado el código de la parte anterior ejecute el siguiente, ¿Que puede decir de los valores de la distribución? Se recomienda hacer modificaciones en el código para realizar un mejor análisis y estudio.


```{r}
# Punto de referencia
# Se recomienda cambiar estos valores por unos adecuados que le permitan estudiar
# Los valores de la distribución de mejor manera
valor_x <- 4
valor_y <- 1

# Grafico

punto_comparacion <- tibble(x = valor_x, y = valor_y)

plt <- data_grid %>%
  ggplot(aes(x = grid_mu, y = grid_sigma)) +
  geom_raster(aes(fill = posterior),
    interpolate = T
  )+ 
  geom_point(x = valor_x, y = valor_y, size = 1.3,color="white")+
  geom_label(
    data = punto_comparacion, aes(x, y),
    label = "Punto Comparación",
    fill = "green",
    color = "black",
    nudge_y = 0, # Este parametro desplaza la caja por el eje y
    nudge_x = 1 # Este parametro desplaza la caja por el eje x
  )+
  scale_fill_viridis_c() +
  labs(
    title = "Posterior para Mean y Standard Deviation",
    x = expression(mu ["Mean"]),
    y = expression(sigma ["Standard Deviation"])
  ) +
  theme(panel.grid = element_blank())

plt

# gráfico para observar datos originales
library(ggplot2)
ggplot(data_notas, aes(Notas)) + geom_histogram(bins = 20, color = "black", fill = "tomato1") + labs(title = "Histograma muestral de notas", x = "Nota", y = "Frecuencia") + theme_light()
```

> **Tras analizar el gráfico, es posible observar que la media $\mu$ esta concentrada en la nota 6, mientras que la desviación estándar esta concentrada entre 0.5 y 0.75. Esto hace sentido pues, como se ve en el histograma, gran parte de las notas están entre 5.5 y 6.5. Además, por el enunciado sabemos que hay una mayor probabilidad (2/3) de que la desviación estándar se concentre en el intervalo $[0.5,1]$, lo que hace sentido con lo mostrado por el gráfico.**  
**Finalmente, situamos el punto de comparación con $\mu = 4$ y $\sigma = 1$. Este punto de comparación es sensato pues, sabemos que las notas están definidas entre 1 y 7, siendo el 4 el punto medio en el intervalo (y además, la nota mínima para aprobar). En ese sentido, concluimos que la posterior para ambos parámetros se sitúa lejos del punto de comparación.**

- [ ] A continuación se presenta un código que permite realizara la distribución dada por sampling from grid approximation ¿Para que sirve este proceso? ¿Que puede deducir del gráfico?

```{r}
# Codificamos los datos
x <- 1:length(data_grid$posterior)

# Sampleamos los indices
posterior_samples_aux <- sample(x,size = 1e4, replace = T, prob = data_grid$posterior)

# Obtenemos los verdaderos valores de la sampling distribution
posterior_samples <- data_grid[posterior_samples_aux,]

# Obtenemos solos los valores relevantes para la densidad
df <- data.frame(posterior_samples$grid_mu,posterior_samples$grid_sigma)

# Realizamos las densidades
dens(df)
```

> **Finalmente, en el gráfico notamos la sampling distribution de los parámetros $\mu$ y $\sigma$ (es decir, se obtienen muestras con remplazo de la grilla de parámetros en función de la probabilidad obtenida en el posterior). En ese sentido, si bien observamos que la densidad se concentra en torno a ciertos valores (6 para la media y 0.6 para la desviación) aún observamos incertidumbre, pues existen otros valores en la distribución que también pueden tomar $\mu$ y $\sigma$. La utilidad de esto es que a partir de este análisis se pueden construir cosas como la posterior predictive distribution**.



&nbsp;
<hr />
<p style="text-align: center;">A work by <a href="https://github.com/dccuchile/CC6104">CC6104</a></p>

<!-- Add icon library -->
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.1/css/all.css">

<!-- Add font awesome icons -->
<p style="text-align: center;">
    <a href="https://github.com/dccuchile/CC6104"><i class="fab fa-github" style='font-size:30px'></i></a>
</p>

<p style="text-align: center;">
    <a href="https://discord.gg/XCbQvGs3Uf"><i class="fab fa-discord" style='font-size:30px'></i></a>
</p>

&nbsp;