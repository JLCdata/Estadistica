---
title: "Tarea 5"
output:
  html_document:
    df_print: paged
---

![](banner.png)

<center> <h1>Tarea 5: Bayesian Inference Part II</h1> </center>
<center><strong>CC6104: Statistical Thinking</strong></center>
#### **Integrantes :** 

- Sebastián Tinoco
- Jose Luis Cádiz

#### **Cuerpo Docente:**

- Profesor: Felipe Bravo M.
- Auxiliar: Sebastian Bustos e Ignacio Meza D.
            

#### **Fecha límite de entrega:**

### **Índice:**

1. [Objetivo](#id1)
2. [Instrucciones](#id2)
3. [Referencias](#id3)
2. [Primera Parte: Preguntas Teóricas](#id4)
3. [Segunda Parte: Elaboración de Código](#id5)

### **Objetivo**<a name="id1"></a>

Bienvenid@s a la uuuuultima tarea del curso Statistical Thinking. Esta tarea tiene como objetivo evaluar los contenidos teóricos de la ultima parte del curso, los cuales se enfocan principalmente en aplicar inferencia bayesiana para generar regresiones lineales y estudiar métodos de obtención de la posterior mas poderosos, como es MCMC. Si aún no han visto las clases, se recomienda visitar los enlaces de las referencias.

La tarea consta de una parte teórica que busca evaluar conceptos vistos en clases. Seguido por una parte práctica con el fin de introducirlos a la programación en R enfocada en el análisis estadístico de datos. 

### **Instrucciones:**<a name="id2"></a>

- La tarea se realiza en grupos de **máximo 2 personas**. Pero no existe problema si usted desea hacerla de forma individual.
- La entrega es a través de u-cursos a más tardar el día estipulado en la misma plataforma. A las tareas atrasadas se les descontará un punto por día.
- El formato de entrega es este mismo **Rmarkdown** y un **html** con la tarea desarrollada. Por favor compruebe que todas las celdas han sido ejecutadas en el archivo html.
- Al momento de la revisión tu código será ejecutado. Por favor verifica que tu entrega no tenga errores de compilación.
- No serán revisadas tareas desarrolladas en Python.
- Está **PROHIBIDO** la copia o compartir las respuestas entre integrantes de diferentes grupos.
- Pueden realizar consultas de la tarea a través de U-cursos y/o del canal de Discord del curso. 


### **Referencias:**<a name="id3"></a>

Slides de las clases:

- [Bayesian Linear Regression](https://github.com/dccuchile/CC6104/blob/master/slides/3_3_ST-bayes_lin.pdf)
- [Markov Chain Monte Carlo](https://github.com/dccuchile/CC6104/blob/master/slides/3_4_ST-MCMC.pdf)
- [Model Evaluation and Information Criteria](https://github.com/dccuchile/CC6104/blob/master/slides/4_1_ST-eval.pdf)
- [Directed Graphical Models](https://github.com/dccuchile/CC6104/blob/master/slides/4_2_ST-dag.pdf)


Videos de las clases:

- Bayesian Linear Regression: [video 1](https://youtu.be/DrwhRshBVjM), [video 2](https://youtu.be/lgNMDCzTV9k),  [video 3](https://youtu.be/ajMucPrZDpU), [video 4](https://youtu.be/YSGWWSUMPOk), [video 5](https://youtu.be/Ma9V8Nown9Q)
- Markov Chain Monte Carlo: [video 1](https://youtu.be/gsofPiPBIeU), [video 2](https://youtu.be/EJZWaph61p4),  [video 3](https://youtu.be/jfidS22imJM), [video 4](https://youtu.be/kif9EG-sy2I), [video 5](https://youtu.be/iVgiowZvyZM), [video 6](https://youtu.be/r0BNqctisLg)
- Model Evaluation and Information Criteria: [video 1](https://youtu.be/HCCzwltLVCc), [video 2](https://youtu.be/twpZHZMmKgM),  [video 3](https://youtu.be/ny4SlO3rcTo), [video 4](https://youtu.be/6U7laePWt9M), [video 5](https://youtu.be/vE2VaK9tLV8), [video 6](https://youtu.be/wmBugs36H-4)  
- Directed Graphical Models: [video 1](https://youtu.be/2jnj-7xpK0E), [video 2](https://youtu.be/GZf8uB37noU),  [video 3](https://youtu.be/3EDdNLOrj_4), [video 4](https://youtu.be/cODS9GgepA4), [video 5](https://youtu.be/JA8H-LjAatE), [video 6](https://youtu.be/YXf0wnzvCFM)   

Documentación:

- [rethinking](https://github.com/rmcelreath/rethinking)
- [tidyr](https://tidyr.tidyverse.org)
- [purrr](https://purrr.tidyverse.org)
- [dplyr](https://dplyr.tidyverse.org)
- [ggplot2](https://ggplot2.tidyverse.org/)

# Primera Parte: Preguntas Teóricas<a name="id4"></a>
A continuación, se presentaran diferentes preguntas que abordan las temáticas vistas en clases. Por favor responda cada una de estas preguntas de forma breve, no más de 4 o 5 lineas.

#### **Pregunta 1:**

Señale algunos beneficios (no mas de dos) que nos brinda realizar una regresión lineal bayesiana sobre una regresión ajustada por mínimos cuadrados.

> Una primera ventaja de la regresión lineal bayesiana es su flexibilidad dado que nos permite incorporar la información del prior. En segundo lugar, la regresión lineal bayesiana nos permite interpretar la incertidumbre del modelo de una manera mucho mas enriquecedora. Esto se consigue a través de graficar tanto los intervalos de credibilidad como la posterior predictive distribution.


#### **Pregunta 2:**

A continuación se presenta un modelo de regresión lineal bayesiana:

$$y_i \sim Normal(\mu, \sigma)$$
$$\mu = \beta_0 + \beta_1*x$$
$$\beta_0 \sim Normal(10,2)$$
$$\beta_1 \sim Normal(0,1)$$
$$\sigma \sim Uniform(0,50)$$

En base al modelo presentado, responda las siguientes preguntas:

- [ ] Describa que representa cada una de las lineas del modelo.

> Las ecuaciones hacen referencia a los priors del modelo. La primera ecuación hace referencia a que el **output** distribuye gaussiano con media $\mu$ y varianza $\sigma$. La segunda ecuación establece la relación lineal entre las variables, donde la media del target $\mu$ es equivalente a $\beta_0 + \beta_1 * x$. La tercera ecuación establece que el intercepto distribuye gaussiano con parámetros $\mu_0 = 10$ y $\sigma_0 = 2$. De manera similar, la cuarta ecuación establece que $\beta_1$ es gaussiano con parámetros $\mu_1 = 0$ y $\sigma_1 = 1$ (notar que es un prior regularizador!). Finalmente, la varianza del target viene dado por una uniforme entre 0 y 50.

- [ ] Señale los parámetros que conforman a la regresión lineal. 

> Los parámetros a estimar son $\beta_0$, $\beta_1$ y $\sigma$

- [ ] Que objetivo cumple en el modelo lineal tener una distribución $Normal(0,1)$ en el parámetro $\beta_1$.

> Tal como se mencionó para la primera parte, la distribución $Normal(0,1)$ en el parámetro $\beta_1$ tiene como fin actuar de regularizador. En otras palabras, este prior presiona al modelo a que los coeficientes obtenidos no sean muy grandes en magnitud, previniendo caer en overfitting.

- [ ] Que propiedad de las regresiones lineales nos entrega $sigma$.

> Como se asume un mismo $\sigma$ para todas las observaciones, esto es equivalente a tener homocedasticidad en la regresión lineal (OLS)

#### **Pregunta 3:**

Explique de forma resumida como funciona el algoritmo de Laplace approximation utilizado para la regresión lineal. Señale el porque existe la necesidad de aplicar este modelo y los supuestos que se realizan con este método.

**Respuesta:**

> El gran objetivo de usar Laplace approximation en la regresión lineal es ajustar el posterior a los datos. El primer supuesto importante tras Laplace approximation es que asume que la joint posterior distribuye gaussiana multivariada, es decir $f(\theta_1, ..., \theta_m|d) = N(\vec \mu, \sum)$. Este supuesto es conveniente cuando se tienen distribuciones unimodales y relativamente simétricas. De esta forma, los valores de $\vec \mu$ vienen dados por MAP, es decir $\vec \mu = \vec \theta_{MAP}$. A su vez, los valores de $\sum$ pueden ser calculados a partir de la curvatura cerca del vector de medias. En términos matemáticos, esto equivale a: $\sum = [I(\theta_{MAP})]^{-1}$, donde $I(\theta) = - \frac{d^2}{d\theta^2} \log f(\theta|d)$. Notar que tanto $\vec \theta_{MAP}$ como $\sum$ pueden ser calculados a partir de algoritmos optimizadores iterativos como SGD. Finalmente, Laplace approximation es una técnica sumamente atractiva pues nos evita calcular la evidencia.

#### **Pregunta 4:**
Determine si las siguientes afirmaciones son verdaderas o falsas. Justifique las falsas.

- [F] El algoritmo de metropolis hasting solo funciona si la probabilidad de saltar de B a A es la misma que de A a B.
- [F] El algoritmo de Gibbs funciona en cualquier caso.
- [V] El algoritmo de metropolis hasting y de Gibbs son el mismo algoritmo, pero este ultimo es una variante del primero.

> La primera afirmación es falsa, pues el algoritmo de metropolis hasting puede funcionar incluso cuando con una función prepositora asimétrica. Para esto, se debe hacer uso de la siguiente ecuación: $$r = \frac{p(\theta^{*})/q(\theta^{*}| \theta^{(t-1)})}{p(\theta^{(t-1)}/q(\theta^{(t-1)}|\theta^{*})}$$. Recordar que en las clases se hace distinción entre Metropolis y Metroplis Hastings! Donde el primero solo funciona cuando la función prepositora es simétrica, y el segundo funciona en cualquier caso al incorporar la corrección mencionada.  
Luego, la segunda afirmación es falsa, pues el funcionamiento de Gibbs sampling requiere el uso de prior y likelihoods conjugados, delimitando el uso del algoritmo. 

#### **Pregunta 5:**

El algoritmo de Gibbs es mas eficiente que el de metropolis hasting. ¿Como se logra este efecto? ¿Existe alguna limitante de esta estrategia?

> El algoritmo de Gibbs sampling es una variante de Metropolis-Hastings que usa preposiciones mas eficientes. Esto logra a través de preposiciones adaptativas que se van ajustando de manera inteligente, dependiendo de los valores de los parámetros del momento. A su vez, estas preposiciones dependen del uso de combinaciones conjugadas entre el prior y likelihood, las que como sabemos, generan soluciones analíticas del posterior de un parámetro. Esto último es lo que permite al algoritmo de Gibbs sampling hacer preposiciones inteligentes para converger de manera mas eficiente.
A pesar de la mayor eficiencia, Gibbs sampling tiene 2 grandes limitacione:  
1. Pueden haber casos donde no queremos usar priors conjugados (para tener una mayor libertad en el modelo)  
2. Gibbs sampling no escala con la cantidad de parámetros, por lo que puede ser muy ineficiente cuando se implementan modelos con cientos o miles de parámetros


#### **Pregunta 6:**

De una ventaja y una desventaja del algoritmo HMC.

> Hamiltonian Monte Carlo es un algoritmo que, a pesar de ser mucho mas costoso computacionalmente que Metropolis o Gibbs sampling, entrega propuestas mucho mas eficientes, por lo que necesita menos muestras para describir la distribución del posterior (mejor convergencia). Además, cuando se trabaja con modelos mas complejos de cientos o miles de parámetros, HMC escala mucho mejor que otros algoritmos como Metropolis o Gibbs.
Una gran desventaja de HMC es que necesita ser tuneado para un modelo y un set de datos en particular. Sin embargo, existen librerias como STAN o RSTAN (ULAM) que ayudan en la automatización de ese tuning.

#### **Pregunta 7:**

Nombre y explique dos propiedades que son deseables en una cadena de Markov.

> Para diagnosticar el mal o buen funcionamiento de una cadena de Markov, es útil graficar el traceplot de las muestras. A partir de esta visualización, es posible concluir el cumplimiento de dos propiedades deseables en una cadena de markov:  
1. Estacionariedad: Se busca que la cadena de markov haya convergido a una distribución estacionaria. Visualmente, esto se aprecia cuando las muestras se quedan constantemente en torno a un intervalo fijo de valores (parecido a un ruido blanco).  
2. Buena mezcla: Que las muestras tengan poca autocorrelación (es decir, que cada muestra dependa de la anterior). En otras palabras, lo que se busca es que las muetras sean lo mas independiente posibles entre sí. Visualmente, esto se aprecia cuando no existe una pendiente, por lo que no es posible extraer un patrón de los datos.

#### **Pregunta 8:**

Explique cómo cross-validation, criterios de información y regularización ayudan a mitigar o medir los problemas de underfitting y overfitting.

> Una buena forma de mitigar problemas de underfitting y overfitting en los modelos es a través de la optimización de la out-of-sample deviance. En ese sentido, es posible estimar esta métrica a través de cross-validation, criterios de información y regularización. A continuación, se explica cada uno y como estos impactan en solucionar el underfitting y overfitting:  
1. Cross-validation: Es una técnica para aproximar la out-of-sample deviance y así comparar varios modelos. Trata sobre dividir la muestra en un número n de folds, luego el modelo genera una predicción sobre cada fold usando como conjunto de entrenamiento todos los demás. Finalmente, como se tiene un puntaje para cada fold, se pueden promediar todos los puntajes y así obtener un único puntaje para el modelo. Una variante digna de mencionar es Leave One Out Cross-Validation (LOOCV), donde la cantidad de folds es equivalente a la cantidad de datos en la muestra. Si bien este método es muy robusto, es un método muy costoso computacionalmente.  
2. Criterios de información: Son un grupo de métricas que se pueden calcular a un modelo que permiten construir un estimador teórico de la out-of-sample deviance usando sólo los datos de entrenamiento. Dentro de estas métricas, podemos encontrar:  
- Akaike information criterion (AIC): Es la suma de la desviaciación muestral y 2 veces el número de parámetros a estimar en el modelo. Mientras mas bajo la métrica, mejor. En el enfoque bayesiano, es equivalente a asumir que los priors son uniformes y que el posterior se aproxima a una distribución gaussiana multivariada.  
- Deviance Information Criterion (DIC): Es un criterio de información bayesiano. Es semejante al AIC (ambos asumen que el posterior es una gaussiana multivariada), pero es consciente de los priors informativos, es decir, usa prior distintos a los flat priors. Se calcula a partir de la distribución posterior de la deviance de entrenamiento.  
3. Regularización: Desde el punto de vista frecuentista, la técnica mas común es la ridge regression. Esto lo logra a través de la penalización los grandes valores de $\beta$ en la regresión. Desde el punto de vista bayesiano, esto es equivalente a usar un prior gaussiano centrado en 0 para cada coeficiente $\beta$. La implementación de ambas técnicas, ya sea por el enfoque frecuentista o bayesiano, genera una menor out-of-sample deviance y aumenta la robustez de los modelos al overfitting.

#### **Pregunta 9:**

Diseñe una DAG para un problema causal inventado por usted de al menos 5 nodos (puede basarse en el ejemplo de Eugene Charniak) usando **Dagitty**  y considere que la DAG tenga al menos: una chain, un fork y un collider. Muestre con dagitty todas las independencias condicionales de su DAG. Explique las independencias usando las reglas de d-separación.

> Sebastián quiere saber si su perro Colihue comió su comida. Se describen los siguientes sucesos:  
- Colihue puede ladrar (A)  
- A la vez, Colihue puede ladrar por 2 razones: quiere salir (C) o porque tiene hambre (D)  
- Al mismo tiempo, Colihue puede estar cansado por dar un paseo (B), llegando usualmente con mucha hambre (D)  
- Finalmente, si Colihue tiene hambre probablemente se deba a que no tiene comida en su plato (E).  

A continuación, se muestra el DAG y las independencias condicionales:

```{r}
library(dagitty)
my_dag <- dagitty('dag {
    A [pos="-0.782,-1.130"]
    B [pos="0.505,-1.150"]
    C [pos="-1.385,-0.428"]
    D [pos="-0.158,-0.393"]
    E [pos="-0.120,0.479"]
    A -> C
    A -> D
    B -> D
    D -> E
    }')

plot(my_dag)
impliedConditionalIndependencies(my_dag) # independencias condicionales
```
> Como podemos ver, (A -> D -> E) es una chain, (A -> C, A -> D) es un fork y (A -> D, B -> D) es un collider. Por otro lado, para analizar la d-separación entre dos vértices debemos comprobar primero si son d-conectados. 2 nodos son d-separados si no existe una d-conexión entre ambos. A su vez, la d-conexión entre 2 nodos se da cuando: (i) existe una chain o fork entre ellos y los nodos intermedios no son parte de la evidencia, (ii) existe un collider como nodo descendiente de ambos y el collider o uno de sus descendientes son parte de la evidencia.
Sabiendo esto, notamos que:
- A y B son d-separados, pues no existe una chain o fork entre ellos, ademas que D y E no son parte de a evidencia (aquí es donde se podrían haber convertido en d-conectadoss!)
- B y C son d-separados, pues no existe un chain o fork entre ellos, además que D y E tampoco son parte de la evidencia (como en el caso anterior, si uno de estos elementos es parte de la evidencia, serían d-conectados)

```{r}
dseparated(my_dag, "A", "B")
dseparated(my_dag, "B", "C")

dseparated(my_dag, "A", "B", c("D"))
dseparated(my_dag, "B", "C", c("E"))
```


---

# Segunda Parte: Elaboración de Código<a name="id5"></a>
En la siguiente sección deberá resolver cada uno de los experimentos computacionales a través de la programación en R. Para esto se le aconseja que cree funciones en R, ya que le facilitará la ejecución de gran parte de lo solicitado.

Para el desarrollo preste mucha atención en los enunciados, ya que se le solicitará la implementación de métodos sin uso de funciones predefinidas. Por otro lado, Las librerías permitidas para desarrollar de la tarea 4 son las siguientes:

```{r, warning = FALSE, message = FALSE}
# Manipulación de estructuras
library(tidyverse)
library(dplyr)
library(tidyr)

# Para realizar plots
library(scatterplot3d)
library(ggplot2)
library(plotly)

# Manipulación de varios plots en una imagen.
library(gridExtra)

# Análisis bayesiano
library("rethinking")
```

Si no tiene instalada la librería “rethinking”, ejecute las siguientes líneas de código para instalar la librería:

```{r, eval=FALSE}
install.packages("rethinking")
```

En caso de tener problemas al momento de instalar la librería con el código anterior, utilice las siguiente chunk:

```{r, eval=FALSE}
install.packages(c("mvtnorm","loo","coda"), repos="https://cloud.r-project.org/",dependencies=TRUE)
options(repos=c(getOption('repos'), rethinking='http://xcelab.net/R'))
install.packages('rethinking',type='source')
```


### Pregunta 1: Regresión Lineal Bayesiana

El objetivo de esta pregunta es introducirlo en la aplicación de una regresión bayesiana. Con esto, buscaremos entender como calcular una regresión bayesiana en base al "motor" aproximación de Laplace, revisando como se comporta la credibilidad de sus predicciones y como la regresión lineal puede llegar a mutar a aplicar una transformación en el vector $x$. Para responder esta pregunta centre su desarrollo solo en las clases y las funciones que nos brinda la librería `rethinking`.

Unos expertos en alometría deciden realizar un estudio de las alturas de unos niños en un colegio, buscando generar un regresor lineal bayesiano capaz de predecir la altura en base al peso de los alumnos. Para realizar este trabajo recopilan los datos `table_height.csv`, quien posee observaciones fisiológicas de 192 alumnos.

**Parte I**

En conocimiento los datos recopilados por los expertos, le solicitan realizar la siguiente serie de tareas:

```{r}
data <- read.csv('table_height.csv')
summary(data) # notamos que existen niños con 0 años de edad
```

- [ ] Defina un modelo de regresión bayesiana, definiendo sus propios priors. Comente cada una de sus asunciones y señale a través de ecuaciones el modelo. Para definir los priors puede ser interesante la información recopilada en el siguiente link: [Priors](https://stacks.cdc.gov/view/cdc/100478)

>Considerando que se desea modelar la altura del niño en base a su peso (es decir, un único regresor aparte del intercepto), los parámetros bayesianos quedan definidos por:  
Likelihood: $y_i$ ~ $N(\mu_i, \sigma)$  (se asume que distribuye normal)  
Modelo lineal: $\mu_i = \beta_0 + \beta_1 x_i$  
Prior $\beta_0$: $\beta_0$ ~ $N(115, 30)$  
Prior $beta_1$: $\beta_1$ ~ $N(0, 1)$  
Prior $\sigma$: $\sigma$ ~ $Uniform(0, 50)$  
De los supuestos del modelo se desprenden las primeras 2 ecuaciones: (i) se asume que la variable objetivo tiene distribución gaussiana y (ii) existe una relación lineal entre las variables de entrada y las de salida.  
Por otro lado, se asume un prior para $\beta_0$ conservador con media 115 y varianza 30. Esto hace que el $\beta_0$ pueda cubrir gran parte de las alturas en los datos (desde 55 a 175 cm), además de dar poca probabilidad a los valores negativos. Por otro lado, esto hace sentido con el informe (https://stacks.cdc.gov/view/cdc/100478), pues se muestra que las alturas varian entre 90 y 175 cm para los ninños (notar que los 90 centimetros son válidos para los niños de 2 años, como en la base de datos hay niños de 0 años se tuvo que ampliar un poco el margen!)  
Para $\beta_1$, se escoge un *prior regularizador* (Normal con media 0 y desviacion 1). Con estos parámetros, el modelo hará que los coeficientes asignados no sean muy grandes, previniendo de paso overfitting.  
Por último, para $\sigma$ se escoge una uniforme entre 0 y 50. La desviación debe ser positiva, por lo que se escoge un mínimo de 0. Se escoge un límite de 50, pues eso implicaría que el 95% de las alturas estaría 100 cm sobre o bajo la altura promedio.

- [ ] Ajuste el modelo lineal utilizando el método de Laplace approximation. Estudie a través del comando `precis` los resultados obtenidos y coméntelos.

```{r}
# declaramos el modelo probabilistico bayesiano
model <- quap (
  alist(
    height ~ dnorm(mu, sigma),
    mu <- b0 + b1*weight,
    b0 ~ dnorm(115 , 30) ,
    b1 ~ dnorm(0 , 1) ,
    sigma ~ dunif(0 , 50)
  ), data=data)
precis(model, prob = 0.95)
```

> De acuerdo a los resultados del modelo, obtenemos las siguientes conclusiones:  
- Con un 95% de credibilidad, la altura base de un alumno se situa entre 55.85 y 61.32 centímetros
- Un kilo adicional aumenta (en promedio) 2.7 centímetros la altura. Además, se observa que 0 no está en el intervalo de credibilidad de $\beta_1$, lo que nos hace pensar que existe una relación lineal entre altura y peso.  
- Finalmente, la altura tiene una desviación $\sigma = 8.44$, lo que hace sentido con la información expuesta en https://stacks.cdc.gov/view/cdc/100478)

- [ ] Gráfique el MAP de regresión lineal obtenida, añadiendo al gráfico el intervalo del $95\%$ que se tiene sobre la media y los valores predecidos de la altura. Comente los resultados obtenidos y señale si su modelo logra ser un buen predictor de los valores estudiados.

```{r}
post <- extract.samples(model, n = 10000) # obtengo muestras del posterior
weight.seq <- seq(from = 0, to = 50, length.out = 50) # secuencia de xs

mu.link <- function(weight) post$b0 + post$b1 * weight # obtenemos la posterior para cada uno de estos valores, obteniendo 1000 valores para cada posible mu
mu <- sapply(weight.seq, mu.link) # aplicamos mu.link
mu.mean <- apply(mu, 2, mean) # obtengo la altura promedio para cada uno de los pesos
mu.HDPI <- apply(mu, 2, HPDI, prob = 0.95)

# intervalo para la altura
height.weight <- function(weight)
  rnorm(
    n = nrow(post),
    mean = post$b0 + post$b1 * weight,
    sd = post$sigma
  )

sim.height <- sapply(weight.seq, height.weight)
height.HPDI <- apply(sim.height, 2, HPDI, prob = 0.95)


plot(height ~ weight, data = data, col = col.alpha(rangi2, 0.5)) # grafico los datos
lines(weight.seq, mu.mean) # grafico la regresion
shade(mu.HDPI, weight.seq) # agrego intervalo de credibilidad para mu 95%
shade(height.HPDI, weight.seq) # agrego intervalo de credibilidad para las alturas 95%
```

> Se observa que, en general, existe un ajuste no tan lejano a los datos. El grueso de los datos quedan muy cerca de la recta, sin embargo, los extremos (datos con poco y mucho peso) se ven algo distantes de la recta, por lo que probablemnete sea necesario incorporar algún ajuste al modelo. Otro aspecto importante es que, si bien la *posterior predictive distribution* contiene a la mayoría de los puntos, las alturas de igual manera estan lejanas del intervalo de credibilidad de la media (intervalo mas oscuro). Una alternativa sería incorporar mas variables a la regresión.


**Parte II**

En base a los resultados obtenidos, el experto que trabaja con usted le señala que las alturas se suelen modelas con pesos logarítmicos, por lo que le sugiere añadir un logaritmo natural en el vector $x$ que compone su modelo lineal. Realice nuevamente la regresión utilizando un intervalo del $95\%$ sobre la media y los valores predecidos de la altura. Comente los resultados obtenidos, señalando si el modelo logra ajustar mejor los valores.

> Dado que los pesos ahora están en escala logarítmica, es necesario cambiar el prior de $\beta_1$. Como el logaritmo de R está en base 10, debemos cambiar el prior en proporción a su base logarítmica (es decir, el prior debe tomar un valor N(0, 10) en adelante). Después de probar con diferentes parámetros, se llegó a la conclusión que $\beta_1$ converge con un prior $N(0,20)$. Por otro lado, se observa que si los prior del modelo no estaban sujetos a cambios, el modelo no alcanza a ajustarse y por lo tanto, obtiene malos resultados.
 
```{r}
# declaramos el modelo probabilistico bayesiano
model2 <- quap (
  alist(
    height ~ dnorm(mu, sigma),
    mu <- b0 + b1*log(weight),
    b0 ~ dnorm(115 , 30),
    b1 ~ dnorm(0, 20), # nuevos valores del prior
    sigma ~ dunif(0 , 50)
  ), data=data)
precis(model2, prob = 0.95)
```

> Con la transformacion logarítmica de los pesos, los coeficientes cambian. A continuación, se presenta una rápida interpretración de los resultados:  
- Según el modelo, la altura mínima de un alumno es negativa. Esto solo tiene sentido si se analiza en conjunto con el logaritmo del peso, pues en términos netos se observan buenos resultados.  
- Para $\beta_1$ la interpretación cambia: como se tienen logaritmos, ahora por unidad de peso adicional se obtienen $\log(weight) \cdot \beta_1$ centímetros adicionales. Una interpretación adicional es leerlo como la derivada del logaritmo: por cada punto porcentual adicional en el peso, se obtiene $\frac{\beta_1}{100}$ centímetros adicionales.  
- Finalmente, la altura tiene una desviación $\sigma = 4.66$, teniendo una desviación menor que el modelo lineal

```{r}
post <- extract.samples(model2, n = 10000) # obtengo muestras del posterior
weight.seq <- seq(from = 0, to = 50, length.out = 50) # secuencia de xs

mu.link <- function(weight) post$b0 + post$b1 * log(weight) # obtenemos la posterior para cada uno de estos valores, obteniendo 1000 valores para cada posible mu
mu <- sapply(weight.seq, mu.link) # aplicamos mu.link
mu.mean <- apply(mu, 2, mean) # obtengo la altura promedio para cada uno de los pesos
mu.HDPI <- apply(mu, 2, HPDI, prob = 0.95)

# intervalo para la altura
height.weight <- function(weight)
  rnorm(
    n = nrow(post),
    mean = post$b0 + post$b1 * log(weight),
    sd = post$sigma
  )

sim.height <- sapply(weight.seq, height.weight)
height.HPDI <- apply(sim.height, 2, HPDI, prob = 0.95)


plot(height ~ weight, data = data, col = col.alpha(rangi2, 0.5)) # grafico los datos
lines(weight.seq, mu.mean) # grafico la regresion
shade(mu.HDPI, weight.seq) # agrego intervalo de credibilidad para mu 95%
shade(height.HPDI, weight.seq) # agrego intervalo de credibilidad para las alturas 95%
```

> Como conclusión, notamos que el modelo con la transformación logarítmica tiene un ajuste mucho mejor que el modelo lineal. Esto se concluye a partir de que los puntos estan mas apegados a la recta y a la altura promedio $\mu_i$. Por otro lado, la mayor parte de los puntos esta dentro de la *posterior predictive distribution*, lo que nos habla de un buen modelo.



#### **Pregunta 2:** MCMC

El objetivo de esta pregunta es lograr samplear, mediante la técnica de MCMC, la distribución gamma. 

En general la distribución gamma se denota por $\Gamma(\alpha,\beta)$ donde $\alpha$ y $\beta$ son parámetros positivos, a $\alpha$ se le suele llamar "shape" y a $\beta$ "rate". La densidad no normalizada de una distribución gamma esta dada por:

$$
f(x\mid \alpha,\beta) = 
\begin{cases}
 x^{\alpha -1}e^{-\beta x} ~ &\text{ si } x > 0\\
0 ~&\text{si } x \leq 0
\end{cases}
$$

- [ ] Implemente el algoritmo de metropolis hasting utilizando $q(\theta^{(t)} \mid \theta^{(t-1)}) = \mathcal{N}(\theta^{t-1},1)$, **importante** su función tiene que poder recibir:
  - [ ] La condición inicial $\theta_{0}$.
  - [ ] Cantidad de repeticiones.
  - [ ] $\alpha$ y $\beta$.
  
  Escriba el algoritmo sin utilizar implementaciones de la distribución gamma en r. 
  
```{r}
# definimos una función que retorne la densidad no normalizada de la distribución gamma
gamma <- function(x, alpha, beta){
  if(x > 0){
    output <- x^(alpha - 1) * exp(-beta*x)
    return(output)
  }else{
    return(0)
  }
}

# función con el algoritmo metropolis hastings
metropolis <- function(current_theta, n_rep, alpha, beta){
  if (current_theta <= 0){
    return("El valor inicial debe ser mayor que cero!")
  }
  thetas <- rep(0, n_rep) # creamos un vector que almacenará las muestras
  for (i in 1:n_rep){ # loop
    thetas[i] <- current_theta # guardamos el valor actual
    
    proposal <- rnorm(1, current_theta, 1) # obtenemos un nuevo theta propuesto
    
    # move?
    prob_move <- min(gamma(proposal, alpha, beta)/gamma(current_theta, alpha, beta), 1) # probabilidad de moverse al nuevo theta
    decision <- rbinom(1, 1, prob_move) # decision de moverse
    current_theta <- ifelse(decision == 1, proposal, current_theta) # actualizo valor de theta actual
  }
  return(thetas)
}

gamma_test <- metropolis(current_theta = 1,  n_rep = 1e4, alpha = 1, beta = 1)

library(rethinking)
dens(gamma_test) # grafico de prueba
```  

De ahora en adelante considere $\alpha = 5$ y $\beta = \frac{1}{5}$.

  - [ ] Considere $\theta_{0} = 1$, grafique el histograma que obtiene para distintas cantidad de repeticiones, entre sus pruebas tiene que tener al menos una que tenga del orden de $10^5$ repeticiones ¿Como cambia la distribución en funcion de las repeticiones?
  - [ ] Considere distintos valores de $\theta_{0}$ y una cantidad de repeticiones grande (del orden de $10^5$), grafique las distribuciones que obtenga comente sus resultados  ¿es importante la condición inicial del algoritmo?.
  - [ ] Utilizando $\theta_{0}$ y cantidad de repeticiones conveniente (de acuerdo a lo que obtuvo en las partes anteriores) compare con la distribución real. **Obs:** En esta parte puede utilizar la distribución gamma que tiene implementado r para comparar con lo que usted realizo.

**Respuesta:**

```{r}
dens(metropolis(current_theta = 1, n_rep = 1e3, alpha = 5, beta = 1/5)) # mcmc con 1000 repeticiones
dens(metropolis(current_theta = 1, n_rep = 1e4, alpha = 5, beta = 1/5)) # mcmc con 10000 repeticiones
dens(metropolis(current_theta = 1, n_rep = 1e5, alpha = 5, beta = 1/5)) # mcmc con 100000 repeticiones
```

Se observa que la densidad de las muestras se va suavizando a medida que aumenta el número de repeticiones. Esto es una clara representación de la Ley de Grandes Números.

Ahora graficamos variando el $\theta_0$:

```{r}
dens(metropolis(current_theta = 3, n_rep = 1e5, alpha = 5, beta = 1/5)) # mcmc basal
dens(metropolis(current_theta = 4, n_rep = 1e5, alpha = 5, beta = 1/5)) # mcmc +1
dens(metropolis(current_theta = 1003, n_rep = 1e5, alpha = 5, beta = 1/5)) # mcmc +1000
```

Se observa que el algoritmo de Metropolis Hastings es robusto a cambios en el valor inicial $\theta_0$. Esto se ve en los siguientes casos:
- Cuando el algoritmo toma un valor inicial $\theta_0 + 1$, el cambio en la densidad es casi imperceptible (gráfico 1 y 2)
- Cuando el algoritmo toma un valor inicial desplazado en una mayor magnitud ($\theta + 1000$), la densidad vuelve a converger a su distribución teórica, solo que tiene que recorrer un camino mas largo para alcanzar la estacionariedad (gráfico 3). En este caso, comienza desde 1003 y disminuye gradualmente hasta el intervalo de mayor frecuencia (0-40)

Finalmente, graficamos la distribución gamma original en contraste con las muestras generadas por el método MCMC:

```{r}
dens(metropolis(current_theta = 1, n_rep = 1e6, alpha = 5, beta = 1/5)) # gamma mediante aproximación mcmc
plot(density(rgamma(n = 1e6, shape = 5, rate = 1/5))) # gamma teórica
```

Notamos que el algoritmo Metropolis Hastings (MCMC) encuentra una buena aproximación a la densidad de la distribución gamma. 

&nbsp;
<hr />
<p style="text-align: center;">A work by <a href="https://github.com/dccuchile/CC6104">CC6104</a></p>

<!-- Add icon library -->
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.1/css/all.css">

<!-- Add font awesome icons -->
<p style="text-align: center;">
    <a href="https://github.com/dccuchile/CC6104"><i class="fab fa-github" style='font-size:30px'></i></a>
</p>

<p style="text-align: center;">
    <a href="https://discord.gg/XCbQvGs3Uf"><i class="fab fa-discord" style='font-size:30px'></i></a>
</p>

&nbsp;